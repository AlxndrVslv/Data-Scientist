{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tt0wTZ1WGSVn"
      },
      "source": [
        "## Установка PySpark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKfUprWiGbxl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8387da7a-a732-41eb-97ab-124085ec29fa"
      },
      "source": [
        "!apt-get update"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Connecting to security.ubuntu.com (185.125.190.82)] [Connected to cloud.r-project.org (3.171.85.\r                                                                                                    \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "\r                                                                                                    \rGet:3 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "\r                                                                                                    \rGet:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\r0% [3 InRelease 127 kB/127 kB 100%] [Waiting for headers] [Connected to cloud.r-project.org (3.171.8\r0% [Waiting for headers] [Connected to cloud.r-project.org (3.171.85.15)] [Connected to r2u.stat.ill\r                                                                                                    \rGet:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:6 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,911 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,526 kB]\n",
            "Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,315 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,682 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,659 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,609 kB]\n",
            "Fetched 20.1 MB in 8s (2,572 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDQwIruzGUfd"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HU_8HXuuGWjf"
      },
      "source": [
        "!wget -q https://archive.apache.org/dist/spark/spark-3.5.4/spark-3.5.4-bin-hadoop3.tgz"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0czFBZLJGYv_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2932a8c2-9f7a-4b63-cbb5-b9952557ee9d"
      },
      "source": [
        "!tar -xvf spark-3.5.4-bin-hadoop3.tgz"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spark-3.5.4-bin-hadoop3/\n",
            "spark-3.5.4-bin-hadoop3/R/\n",
            "spark-3.5.4-bin-hadoop3/R/lib/\n",
            "spark-3.5.4-bin-hadoop3/R/lib/SparkR/\n",
            "spark-3.5.4-bin-hadoop3/R/lib/SparkR/INDEX\n",
            "spark-3.5.4-bin-hadoop3/R/lib/SparkR/R/\n",
            "spark-3.5.4-bin-hadoop3/R/lib/SparkR/R/SparkR\n",
            "spark-3.5.4-bin-hadoop3/R/lib/SparkR/R/SparkR.rdb\n",
            "spark-3.5.4-bin-hadoop3/R/lib/SparkR/R/SparkR.rdx\n",
            "spark-3.5.4-bin-hadoop3/R/lib/SparkR/NAMESPACE\n",
            "spark-3.5.4-bin-hadoop3/R/lib/SparkR/profile/\n",
            "spark-3.5.4-bin-hadoop3/R/lib/SparkR/profile/shell.R\n",
            "spark-3.5.4-bin-hadoop3/R/lib/SparkR/profile/general.R\n",
            "spark-3.5.4-bin-hadoop3/R/lib/SparkR/DESCRIPTION\n",
            "spark-3.5.4-bin-hadoop3/R/lib/SparkR/doc/\n",
            "spark-3.5.4-bin-hadoop3/R/lib/SparkR/doc/sparkr-vignettes.html\n",
            "spark-3.5.4-bin-hadoop3/R/lib/SparkR/doc/sparkr-vignettes.Rmd\n",
            "spark-3.5.4-bin-hadoop3/R/lib/SparkR/doc/index.html\n",
            "spark-3.5.4-bin-hadoop3/R/lib/SparkR/doc/sparkr-vignettes.R\n",
            "spark-3.5.4-bin-hadoop3/R/lib/SparkR/html/\n",
            "spark-3.5.4-bin-hadoop3/R/lib/SparkR/html/00Index.html\n",
            "spark-3.5.4-bin-hadoop3/R/lib/SparkR/html/R.css\n",
            "spark-3.5.4-bin-hadoop3/R/lib/SparkR/help/\n",
            "spark-3.5.4-bin-hadoop3/R/lib/SparkR/help/AnIndex\n",
            "spark-3.5.4-bin-hadoop3/R/lib/SparkR/help/SparkR.rdb\n",
            "spark-3.5.4-bin-hadoop3/R/lib/SparkR/help/SparkR.rdx\n",
            "spark-3.5.4-bin-hadoop3/R/lib/SparkR/help/aliases.rds\n",
            "spark-3.5.4-bin-hadoop3/R/lib/SparkR/help/paths.rds\n",
            "spark-3.5.4-bin-hadoop3/R/lib/SparkR/Meta/\n",
            "spark-3.5.4-bin-hadoop3/R/lib/SparkR/Meta/nsInfo.rds\n",
            "spark-3.5.4-bin-hadoop3/R/lib/SparkR/Meta/features.rds\n",
            "spark-3.5.4-bin-hadoop3/R/lib/SparkR/Meta/Rd.rds\n",
            "spark-3.5.4-bin-hadoop3/R/lib/SparkR/Meta/links.rds\n",
            "spark-3.5.4-bin-hadoop3/R/lib/SparkR/Meta/vignette.rds\n",
            "spark-3.5.4-bin-hadoop3/R/lib/SparkR/Meta/package.rds\n",
            "spark-3.5.4-bin-hadoop3/R/lib/SparkR/Meta/hsearch.rds\n",
            "spark-3.5.4-bin-hadoop3/R/lib/SparkR/worker/\n",
            "spark-3.5.4-bin-hadoop3/R/lib/SparkR/worker/worker.R\n",
            "spark-3.5.4-bin-hadoop3/R/lib/SparkR/worker/daemon.R\n",
            "spark-3.5.4-bin-hadoop3/R/lib/SparkR/tests/\n",
            "spark-3.5.4-bin-hadoop3/R/lib/SparkR/tests/testthat/\n",
            "spark-3.5.4-bin-hadoop3/R/lib/SparkR/tests/testthat/test_basic.R\n",
            "spark-3.5.4-bin-hadoop3/R/lib/sparkr.zip\n",
            "spark-3.5.4-bin-hadoop3/conf/\n",
            "spark-3.5.4-bin-hadoop3/conf/spark-env.sh.template\n",
            "spark-3.5.4-bin-hadoop3/conf/log4j2.properties.template\n",
            "spark-3.5.4-bin-hadoop3/conf/fairscheduler.xml.template\n",
            "spark-3.5.4-bin-hadoop3/conf/workers.template\n",
            "spark-3.5.4-bin-hadoop3/conf/metrics.properties.template\n",
            "spark-3.5.4-bin-hadoop3/conf/spark-defaults.conf.template\n",
            "spark-3.5.4-bin-hadoop3/jars/\n",
            "spark-3.5.4-bin-hadoop3/jars/stream-2.9.6.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/netty-transport-native-epoll-4.1.96.Final-linux-aarch_64.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/avro-1.11.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/spark-repl_2.12-3.5.4.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/activation-1.1.1.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/orc-mapreduce-1.9.5-shaded-protobuf.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/spark-kubernetes_2.12-3.5.4.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/breeze-macros_2.12-2.1.0.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/metrics-core-4.2.19.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/stax-api-1.0.1.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/netty-buffer-4.1.96.Final.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/jakarta.xml.bind-api-2.3.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/kubernetes-model-gatewayapi-6.7.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/netty-handler-4.1.96.Final.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/zookeeper-3.6.3.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/flatbuffers-java-1.12.0.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/spire_2.12-0.17.0.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/guava-14.0.1.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/jackson-core-asl-1.9.13.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/hive-cli-2.3.9.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/curator-framework-2.13.0.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/spark-network-common_2.12-3.5.4.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/commons-collections4-4.4.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/orc-shims-1.9.5.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/jackson-dataformat-yaml-2.15.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/kubernetes-model-core-6.7.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/transaction-api-1.1.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/aopalliance-repackaged-2.6.1.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/hive-beeline-2.3.9.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/commons-cli-1.5.0.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/javax.jdo-3.2.0-m3.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/JTransforms-3.1.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/kubernetes-client-api-6.7.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/spark-hive-thriftserver_2.12-3.5.4.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/scala-compiler-2.12.18.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/netty-common-4.1.96.Final.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/json4s-ast_2.12-3.7.0-M11.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/orc-core-1.9.5-shaded-protobuf.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/spire-util_2.12-0.17.0.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/hive-shims-common-2.3.9.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/spark-graphx_2.12-3.5.4.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/spark-sql_2.12-3.5.4.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/algebra_2.12-2.0.1.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/logging-interceptor-3.12.12.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/kubernetes-model-common-6.7.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/libthrift-0.12.0.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/jakarta.annotation-api-1.3.5.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/scala-collection-compat_2.12-2.7.0.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/annotations-17.0.0.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/commons-collections-3.2.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/hive-llap-common-2.3.9.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/log4j-core-2.20.0.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/spark-common-utils_2.12-3.5.4.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/hadoop-client-api-3.3.4.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/parquet-encoding-1.13.1.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/ivy-2.5.1.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/spark-mesos_2.12-3.5.4.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/jpam-1.1.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/hive-exec-2.3.9-core.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/kubernetes-model-admissionregistration-6.7.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/netty-all-4.1.96.Final.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/parquet-column-1.13.1.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/spark-catalyst_2.12-3.5.4.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/antlr4-runtime-4.9.3.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/slf4j-api-2.0.7.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/janino-3.1.9.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/scala-library-2.12.18.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/kubernetes-model-flowcontrol-6.7.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/jackson-datatype-jsr310-2.15.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/httpcore-4.4.16.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/okhttp-3.12.12.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/jsr305-3.0.0.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/snakeyaml-2.0.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/datasketches-memory-2.1.0.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/jersey-server-2.40.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/jackson-module-scala_2.12-2.15.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/netty-transport-native-kqueue-4.1.96.Final-osx-x86_64.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/osgi-resource-locator-1.0.3.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/zjsonpatch-0.3.0.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/parquet-common-1.13.1.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/parquet-hadoop-1.13.1.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/istack-commons-runtime-3.0.8.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/gson-2.2.4.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/derby-10.14.2.0.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/minlog-1.3.0.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/kubernetes-model-batch-6.7.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/commons-pool-1.5.4.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/arrow-format-12.0.1.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/kubernetes-model-policy-6.7.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/oro-2.0.8.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/jackson-mapper-asl-1.9.13.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/jackson-core-2.15.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/hive-jdbc-2.3.9.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/hive-storage-api-2.8.1.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/netty-handler-proxy-4.1.96.Final.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/hive-shims-0.23-2.3.9.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/hive-shims-2.3.9.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/kubernetes-client-6.7.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/kubernetes-model-rbac-6.7.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/py4j-0.10.9.7.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/log4j-slf4j2-impl-2.20.0.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/jakarta.validation-api-2.0.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/spark-core_2.12-3.5.4.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/jcl-over-slf4j-2.0.7.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/commons-codec-1.16.1.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/spark-mllib_2.12-3.5.4.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/commons-lang-2.6.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/HikariCP-2.5.1.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/kubernetes-model-coordination-6.7.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/avro-ipc-1.11.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/jackson-annotations-2.15.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/commons-dbcp-1.4.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/ST4-4.0.4.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/tink-1.9.0.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/kubernetes-model-storageclass-6.7.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/javolution-5.5.1.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/jersey-common-2.40.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/hive-service-rpc-3.1.3.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/arpack-3.0.3.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/opencsv-2.3.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/jdo-api-3.0.1.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/datanucleus-core-4.1.17.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/cats-kernel_2.12-2.1.1.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/netty-transport-native-kqueue-4.1.96.Final-osx-aarch_64.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/json4s-core_2.12-3.7.0-M11.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/hadoop-shaded-guava-1.1.1.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/jersey-hk2-2.40.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/rocksdbjni-8.3.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/commons-compiler-3.1.9.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/json4s-jackson_2.12-3.7.0-M11.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/RoaringBitmap-0.9.45.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/snakeyaml-engine-2.6.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/jersey-container-servlet-core-2.40.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/netty-codec-4.1.96.Final.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/hive-common-2.3.9.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/compress-lzf-1.1.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/kubernetes-model-apps-6.7.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/netty-transport-native-unix-common-4.1.96.Final.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/netty-transport-classes-epoll-4.1.96.Final.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/datanucleus-api-jdo-4.2.4.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/spark-unsafe_2.12-3.5.4.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/libfb303-0.9.3.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/jackson-databind-2.15.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/shims-0.9.45.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/metrics-graphite-4.2.19.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/zookeeper-jute-3.6.3.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/kubernetes-httpclient-okhttp-6.7.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/hive-serde-2.3.9.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/hk2-locator-2.6.1.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/spark-launcher_2.12-3.5.4.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/kubernetes-model-certificates-6.7.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/netty-codec-http2-4.1.96.Final.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/spark-mllib-local_2.12-3.5.4.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/joda-time-2.12.5.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/mesos-1.4.3-shaded-protobuf.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/commons-crypto-1.1.0.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/curator-recipes-2.13.0.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/spark-sql-api_2.12-3.5.4.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/arrow-vector-12.0.1.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/datasketches-java-3.3.0.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/arrow-memory-netty-12.0.1.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/kubernetes-model-discovery-6.7.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/kubernetes-model-scheduling-6.7.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/netty-transport-native-epoll-4.1.96.Final-linux-x86_64.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/commons-lang3-3.12.0.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/jul-to-slf4j-2.0.7.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/chill-java-0.10.0.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/aircompressor-0.27.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/netty-codec-socks-4.1.96.Final.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/json4s-scalap_2.12-3.7.0-M11.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/avro-mapred-1.11.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/spark-hive_2.12-3.5.4.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/jta-1.1.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/metrics-jvm-4.2.19.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/spark-kvstore_2.12-3.5.4.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/kubernetes-model-node-6.7.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/okio-1.17.6.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/spire-macros_2.12-0.17.0.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/arrow-memory-core-12.0.1.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/antlr-runtime-3.5.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/spark-tags_2.12-3.5.4.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/log4j-api-2.20.0.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/hive-shims-scheduler-2.3.9.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/parquet-jackson-1.13.1.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/jakarta.servlet-api-4.0.3.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/hk2-api-2.6.1.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/kubernetes-model-networking-6.7.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/paranamer-2.8.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/netty-transport-4.1.96.Final.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/commons-io-2.16.1.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/lapack-3.0.3.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/jakarta.inject-2.6.1.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/bonecp-0.8.0.RELEASE.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/metrics-json-4.2.19.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/kubernetes-model-metrics-6.7.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/spire-platform_2.12-0.17.0.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/lz4-java-1.8.0.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/hadoop-yarn-server-web-proxy-3.3.4.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/objenesis-3.3.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/netty-transport-classes-kqueue-4.1.96.Final.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/zstd-jni-1.5.5-4.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/kryo-shaded-4.0.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/metrics-jmx-4.2.19.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/netty-resolver-4.1.96.Final.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/json-1.8.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/netty-codec-http-4.1.96.Final.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/kubernetes-model-events-6.7.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/jersey-container-servlet-2.40.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/JLargeArrays-1.5.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/spark-streaming_2.12-3.5.4.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/kubernetes-model-autoscaling-6.7.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/audience-annotations-0.5.0.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/breeze_2.12-2.1.0.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/scala-reflect-2.12.18.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/commons-logging-1.1.3.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/super-csv-2.2.0.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/jaxb-runtime-2.3.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/scala-xml_2.12-2.1.0.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/xbean-asm9-shaded-4.23.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/datanucleus-rdbms-4.1.19.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/spark-yarn_2.12-3.5.4.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/commons-compress-1.23.0.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/chill_2.12-0.10.0.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/jersey-client-2.40.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/univocity-parsers-2.9.1.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/log4j-1.2-api-2.20.0.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/arpack_combined_all-0.1.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/parquet-format-structures-1.13.1.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/commons-text-1.10.0.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/xz-1.9.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/blas-3.0.3.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/hive-metastore-2.3.9.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/javassist-3.29.2-GA.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/spark-network-shuffle_2.12-3.5.4.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/jline-2.14.6.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/threeten-extra-1.7.1.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/snappy-java-1.1.10.5.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/jodd-core-3.5.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/hk2-utils-2.6.1.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/pickle-1.3.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/jakarta.ws.rs-api-2.1.6.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/kubernetes-model-apiextensions-6.7.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/leveldbjni-all-1.8.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/httpclient-4.5.14.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/kubernetes-model-extensions-6.7.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/curator-client-2.13.0.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/commons-math3-3.6.1.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/spark-sketch_2.12-3.5.4.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/kubernetes-model-resource-6.7.2.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/scala-parser-combinators_2.12-2.3.0.jar\n",
            "spark-3.5.4-bin-hadoop3/jars/hadoop-client-runtime-3.3.4.jar\n",
            "spark-3.5.4-bin-hadoop3/kubernetes/\n",
            "spark-3.5.4-bin-hadoop3/kubernetes/dockerfiles/\n",
            "spark-3.5.4-bin-hadoop3/kubernetes/dockerfiles/spark/\n",
            "spark-3.5.4-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/\n",
            "spark-3.5.4-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/R/\n",
            "spark-3.5.4-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/R/Dockerfile\n",
            "spark-3.5.4-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/python/\n",
            "spark-3.5.4-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/python/Dockerfile\n",
            "spark-3.5.4-bin-hadoop3/kubernetes/dockerfiles/spark/Dockerfile\n",
            "spark-3.5.4-bin-hadoop3/kubernetes/dockerfiles/spark/decom.sh\n",
            "spark-3.5.4-bin-hadoop3/kubernetes/dockerfiles/spark/entrypoint.sh\n",
            "spark-3.5.4-bin-hadoop3/kubernetes/tests/\n",
            "spark-3.5.4-bin-hadoop3/kubernetes/tests/decommissioning_cleanup.py\n",
            "spark-3.5.4-bin-hadoop3/kubernetes/tests/pyfiles.py\n",
            "spark-3.5.4-bin-hadoop3/kubernetes/tests/worker_memory_check.py\n",
            "spark-3.5.4-bin-hadoop3/kubernetes/tests/autoscale.py\n",
            "spark-3.5.4-bin-hadoop3/kubernetes/tests/py_container_checks.py\n",
            "spark-3.5.4-bin-hadoop3/kubernetes/tests/python_executable_check.py\n",
            "spark-3.5.4-bin-hadoop3/kubernetes/tests/decommissioning.py\n",
            "spark-3.5.4-bin-hadoop3/data/\n",
            "spark-3.5.4-bin-hadoop3/data/graphx/\n",
            "spark-3.5.4-bin-hadoop3/data/graphx/users.txt\n",
            "spark-3.5.4-bin-hadoop3/data/graphx/followers.txt\n",
            "spark-3.5.4-bin-hadoop3/data/artifact-tests/\n",
            "spark-3.5.4-bin-hadoop3/data/artifact-tests/smallJar.jar\n",
            "spark-3.5.4-bin-hadoop3/data/artifact-tests/junitLargeJar.jar\n",
            "spark-3.5.4-bin-hadoop3/data/artifact-tests/crc/\n",
            "spark-3.5.4-bin-hadoop3/data/artifact-tests/crc/smallJar.txt\n",
            "spark-3.5.4-bin-hadoop3/data/artifact-tests/crc/README.md\n",
            "spark-3.5.4-bin-hadoop3/data/artifact-tests/crc/junitLargeJar.txt\n",
            "spark-3.5.4-bin-hadoop3/data/mllib/\n",
            "spark-3.5.4-bin-hadoop3/data/mllib/sample_movielens_data.txt\n",
            "spark-3.5.4-bin-hadoop3/data/mllib/streaming_kmeans_data_test.txt\n",
            "spark-3.5.4-bin-hadoop3/data/mllib/pic_data.txt\n",
            "spark-3.5.4-bin-hadoop3/data/mllib/pagerank_data.txt\n",
            "spark-3.5.4-bin-hadoop3/data/mllib/sample_kmeans_data.txt\n",
            "spark-3.5.4-bin-hadoop3/data/mllib/sample_lda_data.txt\n",
            "spark-3.5.4-bin-hadoop3/data/mllib/sample_lda_libsvm_data.txt\n",
            "spark-3.5.4-bin-hadoop3/data/mllib/sample_isotonic_regression_libsvm_data.txt\n",
            "spark-3.5.4-bin-hadoop3/data/mllib/sample_binary_classification_data.txt\n",
            "spark-3.5.4-bin-hadoop3/data/mllib/ridge-data/\n",
            "spark-3.5.4-bin-hadoop3/data/mllib/ridge-data/lpsa.data\n",
            "spark-3.5.4-bin-hadoop3/data/mllib/sample_libsvm_data.txt\n",
            "spark-3.5.4-bin-hadoop3/data/mllib/sample_svm_data.txt\n",
            "spark-3.5.4-bin-hadoop3/data/mllib/images/\n",
            "spark-3.5.4-bin-hadoop3/data/mllib/images/license.txt\n",
            "spark-3.5.4-bin-hadoop3/data/mllib/images/origin/\n",
            "spark-3.5.4-bin-hadoop3/data/mllib/images/origin/multi-channel/\n",
            "spark-3.5.4-bin-hadoop3/data/mllib/images/origin/multi-channel/grayscale.jpg\n",
            "spark-3.5.4-bin-hadoop3/data/mllib/images/origin/multi-channel/chr30.4.184.jpg\n",
            "spark-3.5.4-bin-hadoop3/data/mllib/images/origin/multi-channel/BGRA_alpha_60.png\n",
            "spark-3.5.4-bin-hadoop3/data/mllib/images/origin/multi-channel/BGRA.png\n",
            "spark-3.5.4-bin-hadoop3/data/mllib/images/origin/license.txt\n",
            "spark-3.5.4-bin-hadoop3/data/mllib/images/origin/kittens/\n",
            "spark-3.5.4-bin-hadoop3/data/mllib/images/origin/kittens/54893.jpg\n",
            "spark-3.5.4-bin-hadoop3/data/mllib/images/origin/kittens/29.5.a_b_EGDP022204.jpg\n",
            "spark-3.5.4-bin-hadoop3/data/mllib/images/origin/kittens/DP802813.jpg\n",
            "spark-3.5.4-bin-hadoop3/data/mllib/images/origin/kittens/not-image.txt\n",
            "spark-3.5.4-bin-hadoop3/data/mllib/images/origin/kittens/DP153539.jpg\n",
            "spark-3.5.4-bin-hadoop3/data/mllib/gmm_data.txt\n",
            "spark-3.5.4-bin-hadoop3/data/mllib/kmeans_data.txt\n",
            "spark-3.5.4-bin-hadoop3/data/mllib/sample_multiclass_classification_data.txt\n",
            "spark-3.5.4-bin-hadoop3/data/mllib/als/\n",
            "spark-3.5.4-bin-hadoop3/data/mllib/als/sample_movielens_ratings.txt\n",
            "spark-3.5.4-bin-hadoop3/data/mllib/als/test.data\n",
            "spark-3.5.4-bin-hadoop3/data/mllib/sample_fpgrowth.txt\n",
            "spark-3.5.4-bin-hadoop3/data/mllib/sample_linear_regression_data.txt\n",
            "spark-3.5.4-bin-hadoop3/data/streaming/\n",
            "spark-3.5.4-bin-hadoop3/data/streaming/AFINN-111.txt\n",
            "spark-3.5.4-bin-hadoop3/LICENSE\n",
            "spark-3.5.4-bin-hadoop3/NOTICE\n",
            "spark-3.5.4-bin-hadoop3/RELEASE\n",
            "spark-3.5.4-bin-hadoop3/sbin/\n",
            "spark-3.5.4-bin-hadoop3/sbin/spark-daemon.sh\n",
            "spark-3.5.4-bin-hadoop3/sbin/start-slave.sh\n",
            "spark-3.5.4-bin-hadoop3/sbin/start-thriftserver.sh\n",
            "spark-3.5.4-bin-hadoop3/sbin/spark-daemons.sh\n",
            "spark-3.5.4-bin-hadoop3/sbin/start-mesos-shuffle-service.sh\n",
            "spark-3.5.4-bin-hadoop3/sbin/stop-worker.sh\n",
            "spark-3.5.4-bin-hadoop3/sbin/stop-slaves.sh\n",
            "spark-3.5.4-bin-hadoop3/sbin/stop-history-server.sh\n",
            "spark-3.5.4-bin-hadoop3/sbin/start-history-server.sh\n",
            "spark-3.5.4-bin-hadoop3/sbin/decommission-slave.sh\n",
            "spark-3.5.4-bin-hadoop3/sbin/slaves.sh\n",
            "spark-3.5.4-bin-hadoop3/sbin/stop-mesos-shuffle-service.sh\n",
            "spark-3.5.4-bin-hadoop3/sbin/start-worker.sh\n",
            "spark-3.5.4-bin-hadoop3/sbin/start-mesos-dispatcher.sh\n",
            "spark-3.5.4-bin-hadoop3/sbin/stop-mesos-dispatcher.sh\n",
            "spark-3.5.4-bin-hadoop3/sbin/stop-connect-server.sh\n",
            "spark-3.5.4-bin-hadoop3/sbin/start-all.sh\n",
            "spark-3.5.4-bin-hadoop3/sbin/spark-config.sh\n",
            "spark-3.5.4-bin-hadoop3/sbin/decommission-worker.sh\n",
            "spark-3.5.4-bin-hadoop3/sbin/stop-all.sh\n",
            "spark-3.5.4-bin-hadoop3/sbin/workers.sh\n",
            "spark-3.5.4-bin-hadoop3/sbin/stop-master.sh\n",
            "spark-3.5.4-bin-hadoop3/sbin/stop-thriftserver.sh\n",
            "spark-3.5.4-bin-hadoop3/sbin/start-connect-server.sh\n",
            "spark-3.5.4-bin-hadoop3/sbin/start-master.sh\n",
            "spark-3.5.4-bin-hadoop3/sbin/start-slaves.sh\n",
            "spark-3.5.4-bin-hadoop3/sbin/stop-workers.sh\n",
            "spark-3.5.4-bin-hadoop3/sbin/stop-slave.sh\n",
            "spark-3.5.4-bin-hadoop3/sbin/start-workers.sh\n",
            "spark-3.5.4-bin-hadoop3/examples/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/r/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/r/data-manipulation.R\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/r/RSparkSQLExample.R\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/r/ml/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/r/ml/bisectingKmeans.R\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/r/ml/isoreg.R\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/r/ml/lm_with_elastic_net.R\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/r/ml/ml.R\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/r/ml/naiveBayes.R\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/r/ml/kmeans.R\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/r/ml/fmClassifier.R\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/r/ml/lda.R\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/r/ml/powerIterationClustering.R\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/r/ml/fpm.R\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/r/ml/randomForest.R\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/r/ml/als.R\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/r/ml/decisionTree.R\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/r/ml/survreg.R\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/r/ml/mlp.R\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/r/ml/svmLinear.R\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/r/ml/fmRegressor.R\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/r/ml/gbt.R\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/r/ml/kstest.R\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/r/ml/logit.R\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/r/ml/gaussianMixture.R\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/r/ml/prefixSpan.R\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/r/ml/glm.R\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/r/dataframe.R\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/r/streaming/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/r/streaming/structured_network_wordcount.R\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/resources/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/resources/dir1/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/resources/dir1/file3.json\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/resources/dir1/dir2/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/resources/dir1/dir2/file2.parquet\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/resources/dir1/file1.parquet\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/resources/people.txt\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/resources/kv1.txt\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/resources/META-INF/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/resources/META-INF/services/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/resources/META-INF/services/org.apache.spark.sql.jdbc.JdbcConnectionProvider\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/resources/META-INF/services/org.apache.spark.sql.SparkSessionExtensionsProvider\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/resources/full_user.avsc\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/resources/users.orc\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/resources/users.avro\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/resources/users.parquet\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/resources/people.csv\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/resources/user.avsc\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/resources/employees.json\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/resources/people.json\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRobustScalerExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPowerIterationClusteringExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVarianceThresholdSelectorExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaCorrelationExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaUnivariateFeatureSelectorExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFeatureHasherExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearSVCExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSquareTestExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaSummarizerExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFMRegressorExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSizeHintExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPrefixSpanExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFMClassifierExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaTC.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedUntypedAggregation.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/hive/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedScalar.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedTypedAggregation.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKerberizedKafkaWordCount.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredComplexSessionization.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKerberizedKafkaWordCount.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scripts/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scripts/getGpusResources.sh\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/CorrelationExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FMClassifierExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ChiSquareTestExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FMRegressorExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RobustScalerExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PrefixSpanExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VarianceThresholdSelectorExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorSizeHintExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/UnivariateFeatureSelectorExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/SummarizerExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PowerIterationClusteringExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FeatureHasherExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LinearSVCExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkTC.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/MiniReadWriteTest.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalPi.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/pythonconverters/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalLR.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/SimpleTypedAggregator.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedUntypedAggregation.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/hive/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/jdbc/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/jdbc/ExampleJdbcConnectionProvider.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedTypedAggregation.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedScalar.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredComplexSessionization.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKerberizedKafkaWordCount.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/AccumulatorMetricsTest.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkRemoteFileTest.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/SparkSessionExtensionsTest.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithoutLoader.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithLoader.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/AgeExample.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkLR.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKerberizedKafkaWordCount.scala\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/quantile_discretizer_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/linear_regression_with_elastic_net.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/decision_tree_classification_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/variance_threshold_selector_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/min_hash_lsh_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/string_indexer_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/elementwise_product_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/random_forest_classifier_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/binarizer_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/vector_size_hint_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/feature_hasher_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/gaussian_mixture_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/power_iteration_clustering_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/random_forest_regressor_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/min_max_scaler_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/word2vec_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/interaction_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/estimator_transformer_param_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/linearsvc.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/sql_transformer.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/tokenizer_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/isotonic_regression_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/n_gram_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/vector_assembler_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/imputer_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/multilayer_perceptron_classification.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/max_abs_scaler_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/cross_validator.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/univariate_feature_selector_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/als_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/kmeans_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/normalizer_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/vector_slicer_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/count_vectorizer_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/decision_tree_regression_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/chi_square_test_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/logistic_regression_summary_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/aft_survival_regression.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/prefixspan_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/vector_indexer_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/onehot_encoder_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/tf_idf_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/pca_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/logistic_regression_with_elastic_net.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/fpgrowth_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/dct_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/robust_scaler_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/bucketizer_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/polynomial_expansion_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/lda_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/bisecting_k_means_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/rformula_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/__init__,py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/fm_regressor_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/correlation_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/stopwords_remover_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/index_to_string_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/dataframe_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/fm_classifier_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/generalized_linear_regression_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/train_validation_split.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/naive_bayes_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/summarizer_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/chisq_selector_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/pipeline_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/standard_scaler_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/one_vs_rest_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/parquet_inputformat.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/als.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/transitive_closure.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/wordcount.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/sql/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/sql/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/sql/basic.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/sql/udtf.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/sql/arrow.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/sql/datasource.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/sql/streaming/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/sql/streaming/structured_sessionization.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/sql/streaming/structured_network_wordcount_session_window.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/sql/streaming/structured_network_wordcount.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/sql/streaming/__init__,py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/sql/hive.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/avro_inputformat.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/logistic_regression.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/status_api_demo.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/pagerank.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/sort.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/decision_tree_classification_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/elementwise_product_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/sampled_rdds.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/svm_with_sgd_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/gradient_boosting_regression_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/gaussian_mixture_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/power_iteration_clustering_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/kernel_density_estimation_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/word2vec_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/random_forest_classification_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/gradient_boosting_classification_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/ranking_metrics_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/isotonic_regression_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/word2vec.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/summary_statistics_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/random_forest_regression_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/hypothesis_testing_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/streaming_k_means_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/normalizer_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/binary_classification_metrics_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/k_means_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/decision_tree_regression_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/streaming_linear_regression_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/svd_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/correlations_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/random_rdd_generation.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/tf_idf_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/stratified_sampling_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/logistic_regression.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/fpgrowth_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/regression_metrics_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/multi_class_metrics_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/gaussian_mixture_model.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/pca_rowmatrix_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/recommendation_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/bisecting_k_means_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/correlations.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/naive_bayes_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/kmeans.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/standard_scaler_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/multi_label_metrics_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/mllib/linear_regression_with_sgd_example.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/pi.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/kmeans.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/streaming/\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/streaming/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/streaming/network_wordjoinsentiments.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/streaming/network_wordcount.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/streaming/queue_stream.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/streaming/recoverable_network_wordcount.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/streaming/sql_network_wordcount.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/streaming/stateful_network_wordcount.py\n",
            "spark-3.5.4-bin-hadoop3/examples/src/main/python/streaming/hdfs_wordcount.py\n",
            "spark-3.5.4-bin-hadoop3/examples/jars/\n",
            "spark-3.5.4-bin-hadoop3/examples/jars/scopt_2.12-3.7.1.jar\n",
            "spark-3.5.4-bin-hadoop3/examples/jars/spark-examples_2.12-3.5.4.jar\n",
            "spark-3.5.4-bin-hadoop3/yarn/\n",
            "spark-3.5.4-bin-hadoop3/yarn/spark-3.5.4-yarn-shuffle.jar\n",
            "spark-3.5.4-bin-hadoop3/README.md\n",
            "spark-3.5.4-bin-hadoop3/licenses/\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-jline.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-spire.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-jodd.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-reflectasm.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-kryo.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-graphlib-dot.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-datatables.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-json-formatter.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-janino.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-blas.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-javax-transaction-transaction-api.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-javolution.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-jakarta.xml.bind-api.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-leveldbjni.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-scopt.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-jakarta.activation-api.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-bootstrap.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-f2j.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-xmlenc.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-JLargeArrays.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-machinist.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-JTransforms.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-automaton.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-cloudpickle.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-slf4j.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-javassist.html\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-antlr.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-zstd.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-CC0.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-jquery.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-pyrolite.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-re2j.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-dagre-d3.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-minlog.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-sorttable.js.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-dnsjava.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-jakarta-ws-rs-api\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-matchMedia-polyfill.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-protobuf.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-arpack.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-paranamer.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-join.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-pmml-model.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-vis-timeline.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-mustache.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-modernizr.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-sbt-launch-lib.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-istack-commons-runtime.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-jaxb-runtime.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-zstd-jni.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-jsp-api.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-respond.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-d3.min.js.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-py4j.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-AnchorJS.txt\n",
            "spark-3.5.4-bin-hadoop3/licenses/LICENSE-jakarta-annotation-api\n",
            "spark-3.5.4-bin-hadoop3/bin/\n",
            "spark-3.5.4-bin-hadoop3/bin/run-example\n",
            "spark-3.5.4-bin-hadoop3/bin/spark-class2.cmd\n",
            "spark-3.5.4-bin-hadoop3/bin/sparkR\n",
            "spark-3.5.4-bin-hadoop3/bin/load-spark-env.cmd\n",
            "spark-3.5.4-bin-hadoop3/bin/spark-sql.cmd\n",
            "spark-3.5.4-bin-hadoop3/bin/docker-image-tool.sh\n",
            "spark-3.5.4-bin-hadoop3/bin/pyspark.cmd\n",
            "spark-3.5.4-bin-hadoop3/bin/spark-connect-shell\n",
            "spark-3.5.4-bin-hadoop3/bin/spark-shell.cmd\n",
            "spark-3.5.4-bin-hadoop3/bin/spark-submit\n",
            "spark-3.5.4-bin-hadoop3/bin/spark-submit2.cmd\n",
            "spark-3.5.4-bin-hadoop3/bin/load-spark-env.sh\n",
            "spark-3.5.4-bin-hadoop3/bin/beeline.cmd\n",
            "spark-3.5.4-bin-hadoop3/bin/spark-submit.cmd\n",
            "spark-3.5.4-bin-hadoop3/bin/sparkR.cmd\n",
            "spark-3.5.4-bin-hadoop3/bin/spark-class.cmd\n",
            "spark-3.5.4-bin-hadoop3/bin/spark-shell2.cmd\n",
            "spark-3.5.4-bin-hadoop3/bin/pyspark\n",
            "spark-3.5.4-bin-hadoop3/bin/spark-class\n",
            "spark-3.5.4-bin-hadoop3/bin/sparkR2.cmd\n",
            "spark-3.5.4-bin-hadoop3/bin/find-spark-home\n",
            "spark-3.5.4-bin-hadoop3/bin/spark-sql2.cmd\n",
            "spark-3.5.4-bin-hadoop3/bin/run-example.cmd\n",
            "spark-3.5.4-bin-hadoop3/bin/find-spark-home.cmd\n",
            "spark-3.5.4-bin-hadoop3/bin/spark-shell\n",
            "spark-3.5.4-bin-hadoop3/bin/pyspark2.cmd\n",
            "spark-3.5.4-bin-hadoop3/bin/beeline\n",
            "spark-3.5.4-bin-hadoop3/bin/spark-sql\n",
            "spark-3.5.4-bin-hadoop3/python/\n",
            "spark-3.5.4-bin-hadoop3/python/setup.cfg\n",
            "spark-3.5.4-bin-hadoop3/python/test_support/\n",
            "spark-3.5.4-bin-hadoop3/python/test_support/hello/\n",
            "spark-3.5.4-bin-hadoop3/python/test_support/hello/sub_hello/\n",
            "spark-3.5.4-bin-hadoop3/python/test_support/hello/sub_hello/sub_hello.txt\n",
            "spark-3.5.4-bin-hadoop3/python/test_support/hello/hello.txt\n",
            "spark-3.5.4-bin-hadoop3/python/test_support/test_pytorch_training_file.py\n",
            "spark-3.5.4-bin-hadoop3/python/test_support/userlib-0.1.zip\n",
            "spark-3.5.4-bin-hadoop3/python/test_support/SimpleHTTPServer.py\n",
            "spark-3.5.4-bin-hadoop3/python/test_support/userlibrary.py\n",
            "spark-3.5.4-bin-hadoop3/python/test_support/sql/\n",
            "spark-3.5.4-bin-hadoop3/python/test_support/sql/orc_partitioned/\n",
            "spark-3.5.4-bin-hadoop3/python/test_support/sql/orc_partitioned/b=0/\n",
            "spark-3.5.4-bin-hadoop3/python/test_support/sql/orc_partitioned/b=0/c=0/\n",
            "spark-3.5.4-bin-hadoop3/python/test_support/sql/orc_partitioned/b=0/c=0/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
            "spark-3.5.4-bin-hadoop3/python/test_support/sql/orc_partitioned/b=0/c=0/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
            "spark-3.5.4-bin-hadoop3/python/test_support/sql/orc_partitioned/b=1/\n",
            "spark-3.5.4-bin-hadoop3/python/test_support/sql/orc_partitioned/b=1/c=1/\n",
            "spark-3.5.4-bin-hadoop3/python/test_support/sql/orc_partitioned/b=1/c=1/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
            "spark-3.5.4-bin-hadoop3/python/test_support/sql/orc_partitioned/b=1/c=1/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
            "spark-3.5.4-bin-hadoop3/python/test_support/sql/orc_partitioned/_SUCCESS\n",
            "spark-3.5.4-bin-hadoop3/python/test_support/sql/people_array_utf16le.json\n",
            "spark-3.5.4-bin-hadoop3/python/test_support/sql/people_array.json\n",
            "spark-3.5.4-bin-hadoop3/python/test_support/sql/people1.json\n",
            "spark-3.5.4-bin-hadoop3/python/test_support/sql/ages_newlines.csv\n",
            "spark-3.5.4-bin-hadoop3/python/test_support/sql/text-test.txt\n",
            "spark-3.5.4-bin-hadoop3/python/test_support/sql/streaming/\n",
            "spark-3.5.4-bin-hadoop3/python/test_support/sql/streaming/text-test.txt\n",
            "spark-3.5.4-bin-hadoop3/python/test_support/sql/people.json\n",
            "spark-3.5.4-bin-hadoop3/python/lib/\n",
            "spark-3.5.4-bin-hadoop3/python/lib/pyspark.zip\n",
            "spark-3.5.4-bin-hadoop3/python/lib/PY4J_LICENSE.txt\n",
            "spark-3.5.4-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip\n",
            "spark-3.5.4-bin-hadoop3/python/mypy.ini\n",
            "spark-3.5.4-bin-hadoop3/python/run-tests.py\n",
            "spark-3.5.4-bin-hadoop3/python/MANIFEST.in\n",
            "spark-3.5.4-bin-hadoop3/python/setup.py\n",
            "spark-3.5.4-bin-hadoop3/python/run-tests\n",
            "spark-3.5.4-bin-hadoop3/python/.gitignore\n",
            "spark-3.5.4-bin-hadoop3/python/test_coverage/\n",
            "spark-3.5.4-bin-hadoop3/python/test_coverage/conf/\n",
            "spark-3.5.4-bin-hadoop3/python/test_coverage/conf/spark-defaults.conf\n",
            "spark-3.5.4-bin-hadoop3/python/test_coverage/coverage_daemon.py\n",
            "spark-3.5.4-bin-hadoop3/python/test_coverage/sitecustomize.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/accumulators.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/daemon.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/shell.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/java_gateway.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/broadcast.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/clustering.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/recommendation.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/deepspeed/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/deepspeed/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/deepspeed/deepspeed_distributor.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/deepspeed/tests/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/deepspeed/tests/test_deepspeed_distributor.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/linalg/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/linalg/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/param/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/param/_shared_params_code_gen.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/param/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/param/shared.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/wrapper.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/stat.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/dl_util.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/common.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/base.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/evaluation.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/feature.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/image.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/util.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/_typing.pyi\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/fpm.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tuning.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/model_cache.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/regression.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tree.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/test_persistence.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/tuning/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/tuning/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/tuning/test_cv_io_nested.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/tuning/test_tvs_io_nested.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/tuning/test_tuning.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/tuning/test_cv_io_basic.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/tuning/test_tvs_io_basic.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/tuning/test_tvs_io_pipeline.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/tuning/test_cv_io_pipeline.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/test_base.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/test_linalg.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/test_stat.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/test_pipeline.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/test_functions.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/test_util.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/typing/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/typing/test_param.yml\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/typing/test_feature.yml\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/typing/test_classification.yml\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/typing/test_evaluation.yml\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/typing/test_readable.yml\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/typing/test_clustering.yaml\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/typing/test_regression.yml\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/test_algorithms.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/test_dl_util.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/test_param.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/test_model_cache.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/test_wrapper.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/test_training_summary.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/test_feature.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/test_image.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/test_evaluation.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/connect/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/connect/test_legacy_mode_evaluation.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/connect/test_parity_torch_data_loader.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/connect/test_connect_pipeline.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/connect/test_legacy_mode_pipeline.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/connect/test_connect_summarizer.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/connect/test_legacy_mode_summarizer.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/connect/test_legacy_mode_classification.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/connect/test_connect_evaluation.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/connect/test_connect_feature.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/connect/test_connect_classification.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/connect/test_parity_torch_distributor.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/connect/test_connect_tuning.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/connect/test_legacy_mode_feature.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/connect/test_connect_function.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/tests/connect/test_legacy_mode_tuning.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/classification.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/torch/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/torch/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/torch/torch_run_process_wrapper.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/torch/log_communication.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/torch/distributor.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/torch/data.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/torch/tests/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/torch/tests/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/torch/tests/test_log_communication.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/torch/tests/test_distributor.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/torch/tests/test_data_loader.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/pipeline.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/connect/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/connect/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/connect/io_utils.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/connect/base.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/connect/evaluation.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/connect/feature.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/connect/summarizer.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/connect/util.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/connect/tuning.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/connect/classification.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/connect/pipeline.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/connect/functions.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/ml/functions.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/files.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/version.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/__pycache__/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/__pycache__/install.cpython-38.pyc\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/resource/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/resource/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/resource/requests.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/resource/information.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/resource/tests/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/resource/tests/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/resource/tests/test_resources.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/resource/profile.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/taskcontext.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/profiler.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/conf.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/traceback_utils.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/errors/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/errors/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/errors/exceptions/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/errors/exceptions/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/errors/exceptions/connect.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/errors/exceptions/base.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/errors/exceptions/captured.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/errors/error_classes.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/errors/tests/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/errors/tests/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/errors/tests/test_errors.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/errors/utils.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/install.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/resultiterable.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/catalog.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/readwriter.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/group.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/session.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/window.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/dataframe.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/conf.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/observation.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/context.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/avro/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/avro/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/avro/functions.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/protobuf/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/protobuf/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/protobuf/functions.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/column.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/_typing.pyi\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/udf.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/sql_formatter.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/types.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/udtf.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/test_session.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/test_datasources.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/test_pandas_sqlmetrics.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/test_dataframe.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/test_functions.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/test_catalog.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/typing/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/typing/test_column.yml\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/typing/test_functions.yml\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/typing/test_dataframe.yml\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/typing/test_udf.yml\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/typing/test_readwriter.yml\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/typing/test_session.yml\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/test_udf_profiler.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/test_context.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/test_serde.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/test_errors.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/test_conf.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/test_arrow_map.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/test_arrow.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/test_arrow_python_udf.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/test_readwriter.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/test_types.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/test_column.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/test_utils.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/test_group.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/connect/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_functions.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/connect/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_errors.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/connect/test_session.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_udf_grouped_agg.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/connect/test_connect_basic.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_catalog.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_arrow.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_serde.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_udtf.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_datasources.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/connect/test_connect_plan.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_column.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_cogrouped_map.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_readwriter.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_group.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_arrow_python_udf.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_udf.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_map.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_arrow_map.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_udf_window.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_types.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_udf_scalar.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_grouped_map_with_state.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_dataframe.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/connect/test_connect_column.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/connect/client/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/connect/client/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/connect/client/test_artifact.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/connect/client/test_client.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/connect/test_connect_function.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/connect/test_utils.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_grouped_map.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_conf.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_udf.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/connect/streaming/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/connect/streaming/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/connect/streaming/test_parity_streaming.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/connect/streaming/test_parity_foreach_batch.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/connect/streaming/test_parity_foreach.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/connect/streaming/test_parity_listener.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/test_udf.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/pandas/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/pandas/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_grouped_map.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_udf_window.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_cogrouped_map.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_udf_typehints.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_map.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_udf_typehints_with_future_annotations.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_grouped_map_with_state.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_udf_scalar.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_udf_grouped_agg.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_udf.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/test_udtf.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/streaming/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/streaming/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/streaming/test_streaming_foreach_batch.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/streaming/test_streaming_listener.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/streaming/test_streaming.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/tests/streaming/test_streaming_foreach.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/utils.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/catalog.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/readwriter.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/expressions.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/group.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/session.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/window.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/dataframe.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/conf.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/plan.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/conversion.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/avro/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/avro/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/avro/functions.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/protobuf/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/protobuf/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/protobuf/functions.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/column.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/udf.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/client/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/client/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/client/core.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/client/artifact.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/client/reattach.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/_typing.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/proto/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/proto/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/proto/common_pb2.pyi\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/proto/example_plugins_pb2.pyi\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/proto/example_plugins_pb2.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/proto/expressions_pb2.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/proto/relations_pb2.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/proto/expressions_pb2.pyi\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/proto/relations_pb2.pyi\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/proto/types_pb2.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/proto/base_pb2_grpc.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/proto/catalog_pb2.pyi\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/proto/types_pb2.pyi\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/proto/common_pb2.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/proto/commands_pb2.pyi\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/proto/base_pb2.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/proto/commands_pb2.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/proto/base_pb2.pyi\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/proto/catalog_pb2.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/types.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/udtf.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/utils.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/functions.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/streaming/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/streaming/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/streaming/readwriter.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/streaming/query.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/streaming/worker/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/streaming/worker/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/streaming/worker/listener_worker.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/connect/streaming/worker/foreach_batch_worker.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/functions.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/pandas/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/pandas/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/pandas/map_ops.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/pandas/functions.pyi\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/pandas/_typing/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/pandas/_typing/__init__.pyi\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/pandas/_typing/protocols/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/pandas/_typing/protocols/__init__.pyi\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/pandas/_typing/protocols/frame.pyi\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/pandas/_typing/protocols/series.pyi\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/pandas/conversion.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/pandas/serializers.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/pandas/group_ops.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/pandas/types.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/pandas/typehints.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/pandas/utils.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/pandas/functions.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/streaming/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/streaming/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/streaming/readwriter.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/streaming/query.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/streaming/state.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/sql/streaming/listener.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/context.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/util.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/join.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/storagelevel.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/_typing.pyi\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/cloudpickle/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/cloudpickle/cloudpickle_fast.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/cloudpickle/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/cloudpickle/cloudpickle.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/cloudpickle/compat.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/worker_util.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/rdd.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/testing/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/testing/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/testing/sqlutils.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/testing/pandasutils.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/testing/connectutils.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/testing/streamingutils.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/testing/mllibutils.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/testing/mlutils.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/testing/utils.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/instrumentation_utils.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/worker.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/serializers.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/statcounter.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/rddsampler.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/tests/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/tests/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/tests/test_profiler.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/tests/test_broadcast.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/tests/test_worker.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/tests/test_util.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/tests/typing/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/tests/typing/test_resultiterable.yml\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/tests/typing/test_rdd.yml\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/tests/typing/test_core.yml\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/tests/typing/test_context.yml\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/tests/test_memory_profiler.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/tests/test_appsubmit.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/tests/test_context.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/tests/test_pin_thread.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/tests/test_conf.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/tests/test_shuffle.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/tests/test_taskcontext.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/tests/test_daemon.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/tests/test_stage_sched.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/tests/test_join.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/tests/test_readwrite.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/tests/test_rdd.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/tests/test_rddbarrier.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/tests/test_rddsampler.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/tests/test_install_spark.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/tests/test_statcounter.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/tests/test_serializers.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/mllib/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/mllib/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/mllib/clustering.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/mllib/recommendation.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/mllib/linalg/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/mllib/linalg/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/mllib/linalg/distributed.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/mllib/common.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/mllib/random.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/mllib/evaluation.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/mllib/feature.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/mllib/util.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/mllib/_typing.pyi\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/mllib/fpm.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/mllib/regression.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/mllib/tree.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/mllib/tests/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/mllib/tests/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/mllib/tests/test_linalg.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/mllib/tests/test_stat.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/mllib/tests/test_util.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/mllib/tests/test_streaming_algorithms.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/mllib/tests/test_algorithms.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/mllib/tests/test_feature.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/mllib/stat/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/mllib/stat/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/mllib/stat/test.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/mllib/stat/distribution.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/mllib/stat/_statistics.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/mllib/stat/KernelDensity.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/mllib/classification.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/shuffle.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/find_spark_home.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/_globals.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/py.typed\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/status.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/series.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/sql_processor.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/config.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/mlflow.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/data_type_ops/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/data_type_ops/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/data_type_ops/boolean_ops.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/data_type_ops/binary_ops.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/data_type_ops/datetime_ops.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/data_type_ops/base.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/data_type_ops/categorical_ops.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/data_type_ops/null_ops.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/data_type_ops/string_ops.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/data_type_ops/udt_ops.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/data_type_ops/date_ops.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/data_type_ops/complex_ops.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/data_type_ops/num_ops.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/data_type_ops/timedelta_ops.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/datetimes.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/internal.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/plot/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/plot/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/plot/core.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/plot/plotly.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/plot/matplotlib.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/resample.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/spark/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/spark/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/spark/accessors.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/spark/utils.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/spark/functions.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/strings.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/window.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/indexing.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/extensions.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/numpy_compat.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/accessors.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/base.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/typedef/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/typedef/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/typedef/typehints.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/supported_api_gen.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/usage_logging/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/usage_logging/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/usage_logging/usage_logger.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/categorical.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/correlation.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/groupby.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/exceptions.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/generic.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/sql_formatter.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/_typing.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/series/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/series/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/series/test_as_type.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/series/test_stat.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/series/test_missing_data.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/series/test_cumulative.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/series/test_sort.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/series/test_index.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/series/test_series.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/series/test_arg_ops.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/series/test_compute.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/series/test_conversion.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/series/test_as_of.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/series/test_all_any.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/test_dataframe_spark_io.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/frame/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/frame/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/frame/test_reindexing.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/frame/test_reshaping.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/frame/test_time_series.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/frame/test_spark.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/frame/test_truncate.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/frame/test_take.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/frame/test_attrs.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/frame/test_constructor.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/frame/test_conversion.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/test_internal.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_null_ops.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_complex_ops.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_base.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/testing_utils.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_boolean_ops.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_num_ops.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_num_arithmetic.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_binary_ops.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_categorical_ops.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_date_ops.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_timedelta_ops.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_num_reverse.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_udt_ops.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_datetime_ops.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_string_ops.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/test_indexing.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/test_scalars.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/test_dataframe_conversion.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/plot/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/plot/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/plot/test_series_plot.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/plot/test_series_plot_plotly.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/plot/test_frame_plot_plotly.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/plot/test_frame_plot.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/plot/test_series_plot_matplotlib.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/plot/test_frame_plot_matplotlib.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/test_resample.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/test_numpy_compat.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/test_series_datetime.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/test_series_conversion.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/groupby/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/groupby/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/groupby/test_groupby.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/groupby/test_aggregate.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/groupby/test_split_apply.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/groupby/test_stat.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/groupby/test_missing_data.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/groupby/test_head_tail.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/groupby/test_apply_func.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/groupby/test_cumulative.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/groupby/test_describe.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/groupby/test_index.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/test_generic_functions.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/test_sql.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/test_default_index.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/test_indexops_spark.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/io/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/io/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/io/test_io.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/test_series_string.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/test_rolling.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/test_expanding.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/test_window.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/test_frame_spark.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/test_csv.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/test_config.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby_expanding.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby_rolling.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/test_reshape.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/test_categorical.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/test_typedef.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/test_namespace.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/test_utils.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/test_ewm.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/test_repr.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/computation/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/computation/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/computation/test_any_all.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/computation/test_pivot.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/computation/test_missing_data.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/computation/test_binary_ops.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/computation/test_apply_func.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/computation/test_cumulative.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/computation/test_eval.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/computation/test_describe.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/computation/test_combine.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/computation/test_melt.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/computation/test_compute.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/computation/test_corrwith.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/computation/test_cov.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/test_basic_slow.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/test_align.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/test_setitem_frame.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/test_dot_frame.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/test_setitem_series.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/test_index.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/test_series.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/test_cov_corrwith.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/test_dot_series.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/indexes/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/indexes/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_base.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_align.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_indexing.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_reset_index.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_reindex.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_timedelta.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_category.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_rename.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_datetime.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/test_stats.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/test_spark_functions.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/series/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/series/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_cumulative.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_series.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_missing_data.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_stat.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_conversion.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_as_of.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_index.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_compute.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_sort.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_as_type.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_all_any.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_arg_ops.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_utils.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_internal.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_namespace.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/test_parity_spark.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/test_parity_reshaping.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/test_parity_constructor.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/test_parity_conversion.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/test_parity_truncate.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/test_parity_attrs.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/test_parity_take.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/test_parity_reindexing.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/test_parity_time_series.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_ops_on_diff_frames_groupby_expanding.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/testing_utils.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_num_ops.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_null_ops.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_binary_ops.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_base.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_timedelta_ops.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_categorical_ops.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_num_reverse.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_boolean_ops.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_string_ops.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_date_ops.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_udt_ops.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_num_arithmetic.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_datetime_ops.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_complex_ops.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_frame_spark.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_repr.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_window.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/plot/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/plot/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/plot/test_parity_series_plot_matplotlib.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/plot/test_parity_frame_plot_plotly.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/plot/test_parity_frame_plot.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/plot/test_parity_series_plot.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/plot/test_parity_series_plot_plotly.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/plot/test_parity_frame_plot_matplotlib.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_expanding.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_config.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_typedef.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_generic_functions.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/test_parity_cumulative.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/test_parity_split_apply.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/test_parity_missing_data.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/test_parity_apply_func.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/test_parity_stat.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/test_parity_groupby.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/test_parity_index.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/test_parity_head_tail.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/test_parity_describe.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/test_parity_aggregate.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_spark_functions.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_rolling.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_ewm.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_dataframe_conversion.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_ops_on_diff_frames_groupby.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_stats.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/io/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/io/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/io/test_parity_io.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_numpy_compat.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_indexops_spark.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_series_conversion.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_series_datetime.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_ops_on_diff_frames.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_csv.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_categorical.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_resample.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_scalars.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_extension.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_dataframe_spark_io.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_series_string.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_indexing.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_ops_on_diff_frames_groupby_rolling.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_sql.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_default_index.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_cumulative.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_melt.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_eval.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_missing_data.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_apply_func.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_corrwith.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_combine.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_binary_ops.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_compute.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_describe.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_pivot.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_cov.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_any_all.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/test_parity_series.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/test_parity_dot_series.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/test_parity_index.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/test_parity_cov_corrwith.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/test_parity_align.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/test_parity_setitem_series.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/test_parity_setitem_frame.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/test_parity_dot_frame.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/test_parity_basic_slow.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/test_parity_reset_index.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/test_parity_datetime.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/test_parity_reindex.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/test_parity_base.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/test_parity_category.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/test_parity_align.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/test_parity_indexing.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/test_parity_rename.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/test_parity_timedelta.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_reshape.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/test_extension.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/utils.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/indexes/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/indexes/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/indexes/datetimes.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/indexes/multi.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/indexes/base.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/indexes/category.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/indexes/numeric.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/indexes/timedelta.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/namespace.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/frame.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/missing/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/missing/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/missing/series.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/missing/resample.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/missing/indexes.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/missing/scalars.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/missing/window.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/missing/common.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/missing/general_functions.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/missing/groupby.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/pandas/missing/frame.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/python/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/python/pyspark/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/python/pyspark/shell.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/streaming/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/streaming/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/streaming/kinesis.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/streaming/context.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/streaming/util.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/streaming/dstream.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/streaming/tests/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/streaming/tests/__init__.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/streaming/tests/test_listener.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/streaming/tests/test_context.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/streaming/tests/test_kinesis.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/streaming/tests/test_dstream.py\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark/streaming/listener.py\n",
            "spark-3.5.4-bin-hadoop3/python/dist/\n",
            "spark-3.5.4-bin-hadoop3/python/docs/\n",
            "spark-3.5.4-bin-hadoop3/python/docs/Makefile\n",
            "spark-3.5.4-bin-hadoop3/python/docs/make.bat\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/getting_started/\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/getting_started/quickstart_df.ipynb\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/getting_started/quickstart_ps.ipynb\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/getting_started/install.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/getting_started/testing_pyspark.ipynb\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/getting_started/quickstart_connect.ipynb\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/getting_started/index.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/development/\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/development/setting_ide.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/development/debugging.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/development/errors.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/development/contributing.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/development/index.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/development/testing.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/conf.py\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/pyspark.ss/\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/pyspark.ss/io.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/pyspark.ss/core_classes.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/pyspark.ss/query_management.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/pyspark.ss/index.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/pyspark.ml.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/pyspark.sql/\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/pyspark.sql/catalog.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/pyspark.sql/row.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/pyspark.sql/spark_session.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/pyspark.sql/avro.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/pyspark.sql/io.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/pyspark.sql/protobuf.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/pyspark.sql/grouping.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/pyspark.sql/udtf.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/pyspark.sql/column.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/pyspark.sql/data_types.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/pyspark.sql/udf.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/pyspark.sql/core_classes.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/pyspark.sql/configuration.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/pyspark.sql/dataframe.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/pyspark.sql/window.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/pyspark.sql/index.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/pyspark.sql/functions.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/pyspark.sql/observation.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/pyspark.pandas/\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/pyspark.pandas/groupby.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/pyspark.pandas/ml.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/pyspark.pandas/resampling.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/pyspark.pandas/general_functions.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/pyspark.pandas/io.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/pyspark.pandas/extensions.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/pyspark.pandas/series.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/pyspark.pandas/frame.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/pyspark.pandas/indexing.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/pyspark.pandas/window.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/pyspark.pandas/index.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/pyspark.resource.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/pyspark.mllib.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/pyspark.errors.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/pyspark.streaming.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/pyspark.testing.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/pyspark.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/reference/index.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/user_guide/\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/user_guide/python_packaging.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/user_guide/arrow_pandas.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/typehints.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/best_practices.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/types.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/from_to_dbms.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/faq.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/options.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/transform_apply.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/pandas_pyspark.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/index.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/user_guide/sql/\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/user_guide/sql/python_udtf.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/user_guide/sql/arrow_pandas.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/user_guide/sql/index.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/user_guide/index.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/_static/\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/_static/css/\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/_static/css/pyspark.css\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/migration_guide/\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/migration_guide/koalas_to_pyspark.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/migration_guide/pyspark_upgrade.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/migration_guide/index.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/_templates/\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/_templates/autosummary/\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/_templates/autosummary/class_with_docs.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/_templates/autosummary/class.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/_templates/version-switcher.html\n",
            "spark-3.5.4-bin-hadoop3/python/docs/source/index.rst\n",
            "spark-3.5.4-bin-hadoop3/python/docs/make2.bat\n",
            "spark-3.5.4-bin-hadoop3/python/run-tests-with-coverage\n",
            "spark-3.5.4-bin-hadoop3/python/.coveragerc\n",
            "spark-3.5.4-bin-hadoop3/python/README.md\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark.egg-info/\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark.egg-info/top_level.txt\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark.egg-info/PKG-INFO\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark.egg-info/SOURCES.txt\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark.egg-info/dependency_links.txt\n",
            "spark-3.5.4-bin-hadoop3/python/pyspark.egg-info/requires.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRZMSfoBGacL"
      },
      "source": [
        "!pip install -q findspark"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4gF05a5Gmhm"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.4-bin-hadoop3\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSAJozgMGnwB"
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "sc = spark.sparkContext"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogj228qhHAwN"
      },
      "source": [
        "## Работа с RDD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiMw-VSAGo3M"
      },
      "source": [
        "words = sc.parallelize (\n",
        "   [\"scala\",\n",
        "   \"java\",\n",
        "   \"hadoop\",\n",
        "   \"spark\",\n",
        "   \"akka\",\n",
        "   \"spark\",\n",
        "   \"hadoop\",\n",
        "   \"pyspark\",\n",
        "   \"bigdata\",\n",
        "    \"python\"]\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvlWJllpHC4O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b32f1e0-1894-4abe-afb4-8aaced8da3c4"
      },
      "source": [
        "words"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:289"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZtzVt-hHOO3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46262c64-b05a-43a1-8c91-df1d2d905674"
      },
      "source": [
        "words.count()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bv0Au26PaMZn"
      },
      "source": [
        "def mapper(w):\n",
        "  return (w, 1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nz1PXABQIW3t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cea9f179-19fa-4201-8860-52344a549e29"
      },
      "source": [
        "words.map(mapper)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PythonRDD[2] at RDD at PythonRDD.scala:53"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osteBXqbZlla"
      },
      "source": [
        "transform = words.map(mapper)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0FRlG1MZpui",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "551ee577-8a97-4cfd-fa4b-ccad2bee3397"
      },
      "source": [
        "transform.collect()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('scala', 1),\n",
              " ('java', 1),\n",
              " ('hadoop', 1),\n",
              " ('spark', 1),\n",
              " ('akka', 1),\n",
              " ('spark', 1),\n",
              " ('hadoop', 1),\n",
              " ('pyspark', 1),\n",
              " ('bigdata', 1),\n",
              " ('python', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kW1Sv5osZ3kE"
      },
      "source": [
        "def reducer(a, b):\n",
        "  return a + b"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxTD9-pQbHgx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46a6b1e7-e228-4cf5-b45d-4027256ad270"
      },
      "source": [
        "transform.reduceByKey(reducer)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PythonRDD[8] at RDD at PythonRDD.scala:53"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_2MmlI0bKlT"
      },
      "source": [
        "transform = transform.reduceByKey(reducer)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ger9NE6Zcqea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d3a5996-9417-4181-c406-9e23acf8b95a"
      },
      "source": [
        "transform.collect()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('java', 1),\n",
              " ('hadoop', 2),\n",
              " ('akka', 1),\n",
              " ('python', 1),\n",
              " ('scala', 1),\n",
              " ('spark', 2),\n",
              " ('pyspark', 1),\n",
              " ('bigdata', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bb5fvdXeXtI"
      },
      "source": [
        "## DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCmY3UWJcsQY"
      },
      "source": [
        "df = spark.read.csv('power.csv', inferSchema=True, header=True)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bL3sp-ZX-R6o"
      },
      "source": [
        "## Обзор"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzU537Sc-Tbw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93a756a0-b38f-41eb-ac3a-4069f83fc1a2"
      },
      "source": [
        "df.count()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1189482"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5LVS69P-Vbk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4c64877-c847-40cb-a222-31cadaf9e2c7"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('country', 'string'),\n",
              " ('year', 'int'),\n",
              " ('quantity', 'double'),\n",
              " ('category', 'int')]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxVOAo3F-XLd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e5a73dd-7863-4b37-e38a-d53bab3be264"
      },
      "source": [
        "df.take(2)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(country='Austria', year=1996, quantity=5.0, category=1),\n",
              " Row(country='Austria', year=1995, quantity=17.0, category=1)]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPz3nRfhBxhg"
      },
      "source": [
        "## Практика 1. Загрузите данные из файла transactions.csv. Выведите 10 первых строчек"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTllDnpcBwY8"
      },
      "source": [
        "df_practice = spark.read.csv('transactions.csv', inferSchema = True, header = True)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92AS-jyLB2L1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad5167db-052b-4d0c-88cb-cfabb516b187"
      },
      "source": [
        "df_practice.take(10)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Year=2017, Month=1, ID='t001', Product='A1', Amount=7, Price=2904, Total=20328, Cost=1200),\n",
              " Row(Year=2017, Month=1, ID='t002', Product='A2', Amount=2, Price=1896, Total=3792, Cost=1100),\n",
              " Row(Year=2017, Month=2, ID='t003', Product='A1', Amount=5, Price=2904, Total=14520, Cost=1200),\n",
              " Row(Year=2017, Month=2, ID='t004', Product='A4', Amount=1, Price=8618, Total=8618, Cost=4200),\n",
              " Row(Year=2017, Month=2, ID='t005', Product='A5', Amount=3, Price=5175, Total=15525, Cost=500),\n",
              " Row(Year=2017, Month=2, ID='t006', Product='_6', Amount=4, Price=3500, Total=14000, Cost=200),\n",
              " Row(Year=2017, Month=3, ID='t007', Product='_3', Amount=6, Price=1265, Total=7590, Cost=200),\n",
              " Row(Year=2017, Month=3, ID='t008', Product='_5', Amount=2, Price=5175, Total=10350, Cost=1200),\n",
              " Row(Year=2017, Month=4, ID='t009', Product='_8', Amount=3, Price=3760, Total=11280, Cost=1000),\n",
              " Row(Year=2017, Month=4, ID='t010', Product='_4', Amount=2, Price=8618, Total=17236, Cost=3400)]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E36zGkAO-ZHe"
      },
      "source": [
        "# Выборки"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTeae2v0-eDU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27169833-c622-4826-aecd-5758f7efe91c"
      },
      "source": [
        "df_lim = df.select('country', 'year', 'quantity')\n",
        "df_lim.take(1)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(country='Austria', year=1996, quantity=5.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASxiaM_P-f3O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5108b4d-cb42-4bcb-dbaf-754ea2660cc9"
      },
      "source": [
        "df_lim = df_lim.withColumnRenamed('year', 'y')\n",
        "df_lim"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[country: string, y: int, quantity: double]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncNhRGKE-hvo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dbd65c4-912d-4889-898c-3d79a2496bb2"
      },
      "source": [
        "df_lim.columns"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['country', 'y', 'quantity']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vo5K5V3G-kKr"
      },
      "source": [
        "## Описание и статистики"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dScciVz-nZI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e42468fa-5ea0-4005-91bb-ce7d9ccbd6d7"
      },
      "source": [
        "df_lim.show()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+--------+\n",
            "|country|   y|quantity|\n",
            "+-------+----+--------+\n",
            "|Austria|1996|     5.0|\n",
            "|Austria|1995|    17.0|\n",
            "|Belgium|2014|     0.0|\n",
            "|Belgium|2013|     0.0|\n",
            "|Belgium|2012|    35.0|\n",
            "|Belgium|2011|    25.0|\n",
            "|Belgium|2010|    22.0|\n",
            "|Belgium|2009|    45.0|\n",
            "|Czechia|1998|     1.0|\n",
            "|Czechia|1995|     7.0|\n",
            "|Finland|2010|     9.0|\n",
            "|Finland|2009|    13.0|\n",
            "|Finland|2008|    39.0|\n",
            "|Finland|2007|    21.0|\n",
            "|Finland|2006|     0.0|\n",
            "|Finland|2005|     0.0|\n",
            "|Finland|2004|     0.0|\n",
            "|Finland|2003|     0.0|\n",
            "|Finland|2002|     0.0|\n",
            "|Finland|2001|     0.0|\n",
            "+-------+----+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6ESTSnQ-oKQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0c5a4d8-a875-4502-fd8e-d1e55271750b"
      },
      "source": [
        "df_lim.describe().show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------+------------------+--------------------+\n",
            "|summary|    country|                 y|            quantity|\n",
            "+-------+-----------+------------------+--------------------+\n",
            "|  count|    1189482|           1189482|             1189482|\n",
            "|   mean|       NULL|2002.8515538696677|  184264.77005012735|\n",
            "| stddev|       NULL| 7.167344581291499|1.5856628141359948E7|\n",
            "|    min|Afghanistan|              1990|           -864348.0|\n",
            "|    max|   Zimbabwe|              2014|          6.680329E9|\n",
            "+-------+-----------+------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_tjRcwR-p-d"
      },
      "source": [
        "## Сохранение"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quD2SF92-2gE"
      },
      "source": [
        "df_lim.write.format('com.databricks.spark.csv').option('header', 'true').save('df_lim.csv')"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_k9_emZT_Cyi"
      },
      "source": [
        "## Вычисления"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oStV0Jih_ELx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f383cc52-f93a-42fe-9713-225814e7130d"
      },
      "source": [
        "df_lim = df_lim.withColumn('quantity x 2', df_lim['quantity'] * 2)\n",
        "df_lim.take(2)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(country='Austria', y=1996, quantity=5.0, quantity x 2=10.0),\n",
              " Row(country='Austria', y=1995, quantity=17.0, quantity x 2=34.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7zB2mYn_E7m"
      },
      "source": [
        "df_grp = df_lim.groupBy('country')"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTlaanzf_Gti"
      },
      "source": [
        "df_sum = df_grp.sum('quantity', 'quantity x 2')"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4HHb1EN_Iiu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "168a829b-80cb-4d51-838b-196d1e47a5d9"
      },
      "source": [
        "df_sum.show()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+--------------------+--------------------+\n",
            "|           country|       sum(quantity)|   sum(quantity x 2)|\n",
            "+------------------+--------------------+--------------------+\n",
            "|     Côte d'Ivoire| 2.815485732456253E7| 5.630971464912506E7|\n",
            "|              Chad|  3796498.7491319943|   7592997.498263989|\n",
            "|          Paraguay|     1.23209483765E7|      2.4641896753E7|\n",
            "|          Anguilla|   20529.34999999997|   41058.69999999994|\n",
            "|             Yemen|1.8178937740390217E8|3.6357875480780435E8|\n",
            "|State of Palestine|  1318668.0123446316|   2637336.024689263|\n",
            "|           Senegal|   6944395.348079733|1.3888790696159465E7|\n",
            "|            Sweden|1.3456236759933385E8| 2.691247351986677E8|\n",
            "|        Cabo Verde|   88130.27080000004|  176260.54160000008|\n",
            "|          Kiribati|   6450.091429000002|  12900.182858000004|\n",
            "|            Guyana|   772150.6722661877|  1544301.3445323755|\n",
            "|       Philippines|  8.45277094530091E7| 1.690554189060182E8|\n",
            "|           Eritrea|   918454.1476713057|  1836908.2953426114|\n",
            "|            Jersey|  142744.73085845588|  285489.46171691176|\n",
            "|             Tonga|  16350.450516472933|  32700.901032945865|\n",
            "|          Djibouti|  130946.11799999996|  261892.23599999992|\n",
            "|         Singapore| 4.701454062703839E7| 9.402908125407678E7|\n",
            "|          Malaysia| 8.356959770425016E8|1.6713919540850031E9|\n",
            "|              Fiji|  400739.80509911076|   801479.6101982215|\n",
            "|            Turkey| 3.500108256564667E8| 7.000216513129334E8|\n",
            "+------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmFNR9jX_PRz"
      },
      "source": [
        "## Свободные таблицы"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MU4BiZ4-_KOB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d355360-8baa-4d7a-d26c-2968bee1911c"
      },
      "source": [
        "df_lim.groupby('country').pivot('y').sum('quantity').show()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+--------------------+------------------+------------------+--------------------+------------------+--------------------+------------------+--------------------+------------------+------------------+------------------+------------------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+\n",
            "|           country|                1990|              1991|              1992|                1993|              1994|                1995|              1996|                1997|              1998|              1999|              2000|              2001|              2002|                2003|                2004|                2005|                2006|                2007|                2008|                2009|                2010|               2011|                2012|                2013|                2014|\n",
            "+------------------+--------------------+------------------+------------------+--------------------+------------------+--------------------+------------------+--------------------+------------------+------------------+------------------+------------------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+\n",
            "|     Côte d'Ivoire|  179200.61401456923|138425.21851129067|141628.24086391355|   738118.7649614385| 692451.0545034658|   763166.1221894001| 864136.4834033169|   1578442.983095539|1573981.5852612671| 1724300.573725152|1724840.6538661383|1759341.9700965367| 1763079.381005324|   500333.9493423132|   624320.2734387387|  2368558.8370472165|   693997.7379584936|  2349933.3393531702|  2364487.6081012883|       644995.821018|       687863.824306|  705218.1368339178|   760218.1598216596|        846869.07006|  1966946.9217843462|\n",
            "|              Chad|  27866.899999999994|           28199.1| 28952.38000000001|            30198.92|          30674.78|            31387.54|          31940.18|            32873.64|33596.880000000005|          34443.98|35316.380000000005|183996.10000000006|184713.19999999992|  174366.33993199997|  188480.67299999995|  278986.89139999996|   277915.6906000001|  277236.75599999994|         276468.0642|            276685.5|            277818.3| 260806.39999999994|  260313.91999999993|  260596.83400000003|  272663.39999999997|\n",
            "|          Anguilla|               266.5|246.50000000000003|300.30000000000007|               394.4|             385.5|               353.0|             378.4|               460.8|491.90000000000003|             546.0|             616.8| 710.2000000000002| 723.9000000000001|  1794.2000000000003|               815.8|   927.3000000000001|             1054.65|              1230.8|              1237.1|  1268.6000000000004|              1346.0| 1293.6000000000001|              1235.5|              1219.9|              1231.7|\n",
            "|          Paraguay|           277601.68|          242465.7|         231803.94|  309039.33999999997|         292873.68|           369978.36|         360675.18|           902691.56|421855.94000000006| 421369.9700000001| 429832.0800000001|         382817.85|         396682.73|           418668.49|           559373.97|   688977.4699999997|           572468.45|   583707.6599999999|          721195.322|   604260.3099999999|           607219.97|  623368.6008000001|         640138.8237|            641732.3|   620149.0000000001|\n",
            "|             Yemen|                NULL| 640494.5592000001| 644715.9592000002|     1.73762749592E7| 645474.4392000001|   650430.4392119998| 650613.4392119998|1.9403496439211998E7| 1.9563675479212E7| 1.9573466719212E7| 1.9581821719212E7| 658144.0689639999| 659213.1702239998|       667595.022988|   661977.8272560001|   1.9219612345156E7|   530316.7766839999|   1.8962018087136E7|    2.216455216716E7|   642203.9229320001|      1402382.716584|     1751663.348112|      1549227.017516|       1940676.68692| 1.224933009419814E7|\n",
            "|State of Palestine|   36202.91818670148| 36735.14011881636|37312.768490931245|  37881.471711122715| 38456.84073123759|   39049.98781550566| 39908.45267315928|   42063.28321867711| 44298.13972170757| 44950.58758757528| 46695.02208919756|          47766.66| 54975.32000000001|             54930.8|            57833.12|   57659.04000000001|            55562.36|            65958.54|   63597.45999999999|            65861.14|   63871.26000000001|  69582.19999999998|   71063.09999999999|             69636.4|   76815.99999999999|\n",
            "|           Senegal|  125088.45957738382|45839.163237266235|46258.870200696154|  130864.01226457857| 50085.58512846098|  138426.17539708567| 56695.91888861533|   658458.4279195975| 659571.0492964847| 636792.9921598244|  646902.149222259| 649629.6406886296| 655990.9308528196|   78081.34111924001|   81030.25609971245|  519916.68781935866|   71411.08081135864|       509907.240035|        488011.81008|   103616.2324517584|   110843.5289815176| 118107.69182853911|  121377.62969861804|   118831.0876862042|  122657.38663472484|\n",
            "|            Sweden|   5444557.743840976| 3847982.392992314| 4340571.316368345|   6226557.230980654| 4526221.094142872|   4945046.669404178| 4999657.703339272|   6635639.381501611| 5057647.462508898| 5156978.943618929| 4977924.518337257| 5147677.715927103| 5023504.381497217|   5074266.463601675|   5262612.280787054|   7333826.178431609|    5132509.02791234|   5185654.859879831|   7101914.838531472|   5133700.621783844|   6021501.168581883|  5391268.680895225|    5667540.50574921|   5507651.882320744|  5419954.5363994595|\n",
            "|        Cabo Verde|  1155.1999999999998|1280.0000000000002|1393.2160000000003|  1514.9999999999995|1642.2999999999997|  1727.7999999999997|            1846.1|              1933.5|           2063.56|           2292.74|2641.2378000000003| 2874.050600000001|         3201.4612|  3531.7888000000003|           3786.0174|   4309.248999999998|            4505.295|  4952.4400000000005|  5196.9180000000015|   5446.598000000002|   5745.156000000003|           6076.348|  6106.8219999999965|   6393.830000000002|   6513.643000000002|\n",
            "|          Kiribati|             129.696|131.02599999999998|132.60199999999998|             142.704|           116.634|  151.77200000000002|            153.99|  165.41600000000003|           174.438|193.08298400000004|213.45962600000001|        192.414714|225.66574000000006|          261.400156|          289.432604|          335.203666|          369.381934|          374.746267|  367.38217599999996|  334.69450500000005|  398.99610699999994| 396.00447499999996|  397.25047499999994|             399.166|  403.53200000000004|\n",
            "|            Guyana|             79031.0| 8946.919999999998|10416.039999999999|   78445.99655000001|14251.029662509094|    81784.8712613098| 16063.80125350755|  25410.138297415207|17637.435956491423|18736.248139824824|18605.760172832117|18997.189373416055|19979.239823416054|   18507.14436162045|  19517.438132218973|   79992.95791261314|  15956.129582423357|  17661.854817620435|   98072.68420902187|   17351.99675821898|  18313.910481021885|  19923.62620065427|   19559.20845680192|  19447.527069413787|  19540.523793834363|\n",
            "|            Jersey|                NULL|          3766.826| 4580.893999999999|   4502.718000000001|          4636.554|   4707.274000000001|4697.3859999999995|            4530.232|          4741.026| 4893.022000000001|          4330.844| 4175.629999999999| 5141.223999999999|   5107.246000000001|   5314.898000000001|             5238.44|   6347.340000000001|  6250.3499999999985|             6686.82|   7372.401711223476|   7697.520665878101|  8561.341923693002|   8624.581850573362|  11801.192984424379|   9038.967722663658|\n",
            "|       Philippines|      4872442.668964| 886222.7193100001|     910510.667172|      8144067.944278| 996440.8453820001|  1381127.5184840001|    1097312.419034|      5433349.110208| 4220268.261240001|    4212736.103036| 4221427.107450001|1095741.9812460002|1378160.7776539999|      1565435.729287|      1536699.024523|      6823174.611754|  1565125.7899599997|   6030005.417306552|   6062647.436429797|  2074114.9258400681|  2118374.7117280695| 2204632.6941635874|   2331797.456862689|  2316620.1734896204|1.1049273358206894E7|\n",
            "|           Eritrea|                NULL|              NULL|              NULL|                NULL| 56283.38916400001|        56919.833608| 59071.24849200001|  58436.426928000015|      41378.319648| 41954.86206800001|      42999.131364|      46426.732898|       47837.77285|        49415.203064|        33702.878486|        34576.860424|  35017.888342469625|   36101.50191400001|        36743.081338|        37719.459008|        38817.535086| 39851.182268000004|   40863.97865406021|   41717.22495675972|   42619.63711001641|\n",
            "|          Djibouti|             3751.31|          3802.084|3838.8900000000003|  3912.0020000000004|          3942.562|  4019.8379999999997|           4084.91|            4177.072|          4197.624|4190.5779999999995|4322.9259999999995|          4488.502|          4662.278|            4732.714|  4886.8099999999995|             5601.59|            6006.386|  6352.5019999999995|   6645.541999999999|   6731.942000000001|   7133.442000000001|  7093.641999999999|   7338.941999999999|   7494.635999999999|            7537.394|\n",
            "|             Tonga|             424.706|           458.676| 477.8280000000001|  476.20000000000005| 490.1579999999999|             546.342| 506.3419999999999|   532.1579999999999| 532.8140000000001| 587.3419999999999| 660.3979999999999|           608.164| 632.4959999999999|            731.6682|   740.8119999999999|             745.036|              786.72|   775.0440000000001|   809.9179999999999|             846.156|   784.8720000000001|  782.6699999999998|          783.072382|   805.4329344729344|   825.4250000000002|\n",
            "|          Malaysia|       7.539379154E7|        3630348.76|        4053379.58|       9.066662618E7|        5444714.86|          7372787.72|        7548536.04|       9.697107688E7|        8356655.52|        8816969.94|        9832695.56|      9862562.7215|    1.0156410161E7|1.1290337499499999E7|1.1483888279999997E7|1.1017984589449991E8|1.3568230869999992E7|1.1027958319100001E8|     1.05665704693E8|1.3742594939000003E7|1.4225420097000005E7|     1.4237323005E7|1.3701881655000005E7|1.4927126947999999E7|6.4287484507999994E7|\n",
            "|         Singapore|            666431.8|          702029.8|          809230.4|          1013431.78|        1095529.96|           1097779.0|         1137694.0|  1158149.4000000001|         1181809.2|         1091945.0|1100679.4000000001|         1223220.8|1458131.4000000001|  1781154.7059999995|  2010115.8560000006|  2140600.7800000003|         2248999.072|         2690496.958|  2731579.6926680002|  2909853.4518000004|  3084709.7436260004| 3169217.9893360008|   3307946.704075997|    3547558.79533485|   3656244.938197594|\n",
            "|              Fiji|             12803.0|           15295.0|        15350.1452|  16460.985199999996|17609.305199999995|  17369.047200000005|17070.372999999992|          16186.3492|13529.386199999997|16135.352400000002|        15769.9394|15902.744200000001|16099.855399999997|        16979.423464|  17807.267040000002|  19865.564732000006|  17636.471595999992|        16760.773876|   18721.49689589472|   13247.01256256472|  14443.013048973891| 14371.890012820713|  13561.387769888599|  15474.000906582249|   16290.02059438566|\n",
            "|            Turkey|2.9569912387522005E7|3425278.9956223853| 3624057.548987308|2.8824612418720607E7| 3913937.284074207|1.1756813264992718E7|  4820581.35558611| 2.270850510269465E7| 6079967.987948154| 6539792.504395979| 7325142.089620853| 6897046.789065901| 7300363.438214261|   8209866.647855243|   8591377.562469844| 1.849678879070945E7|1.1345372716818921E7|1.5192788125141894E7|1.6278560425633818E7|1.2287713199032567E7|1.3239476527438216E7|1.494571464621237E7|1.5423897148126835E7|1.5405077044678276E7| 5.780818165490422E7|\n",
            "+------------------+--------------------+------------------+------------------+--------------------+------------------+--------------------+------------------+--------------------+------------------+------------------+------------------+------------------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3hDmhO9CFC_"
      },
      "source": [
        "## Практика 2. Выведите максимальную и минимальную (2 датафрейма) количество (Amount) по продукту"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_practice.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qjc36vhXUuj",
        "outputId": "27f94bc7-b8d7-42d9-bcc0-5e80129b003b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+----+-------+------+-----+-----+----+\n",
            "|Year|Month|  ID|Product|Amount|Price|Total|Cost|\n",
            "+----+-----+----+-------+------+-----+-----+----+\n",
            "|2017|    1|t001|     A1|     7| 2904|20328|1200|\n",
            "|2017|    1|t002|     A2|     2| 1896| 3792|1100|\n",
            "|2017|    2|t003|     A1|     5| 2904|14520|1200|\n",
            "|2017|    2|t004|     A4|     1| 8618| 8618|4200|\n",
            "|2017|    2|t005|     A5|     3| 5175|15525| 500|\n",
            "|2017|    2|t006|     _6|     4| 3500|14000| 200|\n",
            "|2017|    3|t007|     _3|     6| 1265| 7590| 200|\n",
            "|2017|    3|t008|     _5|     2| 5175|10350|1200|\n",
            "|2017|    4|t009|     _8|     3| 3760|11280|1000|\n",
            "|2017|    4|t010|     _4|     2| 8618|17236|3400|\n",
            "|2017|    4|t011|     _2|     4| 1896| 7584| 800|\n",
            "|2017|    4|t012|     _5|     5| 5175|25875| 700|\n",
            "|2017|    4|t013|     _8|     3| 3760|11280|1200|\n",
            "|2017|    4|t014|     _4|     1| 8618| 8618| 250|\n",
            "|2017|    5|t015|     _2|     2| 1896| 3792| 650|\n",
            "|2017|    5|t016|     A4|     3| 8618|25854|2400|\n",
            "|2017|    5|t017|     A5|     2| 5175|10350|1200|\n",
            "|2017|    5|t018|     _6|     4| 3500|14000|1200|\n",
            "|2017|    5|t019|     _3|     5| 1265| 6325| 200|\n",
            "|2017|    5|t020|     _5|     6| 5175|31050| 800|\n",
            "+----+-----+----+-------+------+-----+-----+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KW-k4akCCEBH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1494f61-57c5-4480-d29c-0c4769e85eb3"
      },
      "source": [
        "df_pr_max = df_practice.groupby('Product').max('Amount')\n",
        "df_pr_max.show()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------+\n",
            "|Product|max(Amount)|\n",
            "+-------+-----------+\n",
            "|     _5|          6|\n",
            "|     _2|          8|\n",
            "|     A2|          2|\n",
            "|     _8|         10|\n",
            "|     _3|          7|\n",
            "|     _4|          3|\n",
            "|     _6|          4|\n",
            "|     A4|          3|\n",
            "|     A5|          7|\n",
            "|     A1|          9|\n",
            "+-------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0i1cCCNxCPQ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18e1c594-c67e-4366-bb3f-691a4590bd06"
      },
      "source": [
        "df_pr_min = df_practice.groupby('Product').min('Amount')\n",
        "df_pr_min.show()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------+\n",
            "|Product|min(Amount)|\n",
            "+-------+-----------+\n",
            "|     _5|          1|\n",
            "|     _2|          1|\n",
            "|     A2|          2|\n",
            "|     _8|          1|\n",
            "|     _3|          2|\n",
            "|     _4|          1|\n",
            "|     _6|          4|\n",
            "|     A4|          1|\n",
            "|     A5|          2|\n",
            "|     A1|          2|\n",
            "+-------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNjDfZq5CRPB"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebXiYWMl_UFY"
      },
      "source": [
        "## Подвыборки"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1BX8t-iYKei",
        "outputId": "afbb2cf7-b474-45a9-c70e-76eaba10f1da"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+--------+--------+\n",
            "|country|year|quantity|category|\n",
            "+-------+----+--------+--------+\n",
            "|Austria|1996|     5.0|       1|\n",
            "|Austria|1995|    17.0|       1|\n",
            "|Belgium|2014|     0.0|       1|\n",
            "|Belgium|2013|     0.0|       1|\n",
            "|Belgium|2012|    35.0|       1|\n",
            "|Belgium|2011|    25.0|       1|\n",
            "|Belgium|2010|    22.0|       1|\n",
            "|Belgium|2009|    45.0|       1|\n",
            "|Czechia|1998|     1.0|       1|\n",
            "|Czechia|1995|     7.0|       1|\n",
            "+-------+----+--------+--------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVCYLZaI_Vkg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97b40d4e-8f57-4b56-e10f-334dab93ebe3"
      },
      "source": [
        "df['quantity'] > 184264"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Column<'(quantity > 184264)'>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOYzBPZT_fi8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38390fda-7a68-4769-b1ba-eb6231d3e526"
      },
      "source": [
        "df.where((df['quantity'] > 184264)).show()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----+--------+--------+\n",
            "|      country|year|quantity|category|\n",
            "+-------------+----+--------+--------+\n",
            "|United States|2014|367987.0|       2|\n",
            "|United States|2013|384439.0|       2|\n",
            "|United States|2012|370625.0|       2|\n",
            "|United States|2011|310909.0|       2|\n",
            "|United States|2010|335418.0|       2|\n",
            "|United States|2009|230589.0|       2|\n",
            "|United States|2008|226570.0|       2|\n",
            "|United States|2007|221771.0|       2|\n",
            "|United States|2005|314655.0|       2|\n",
            "|United States|2004|243916.0|       2|\n",
            "|United States|1996|226319.0|       2|\n",
            "|United States|1995|292568.0|       2|\n",
            "|United States|1994|230254.0|       2|\n",
            "|United States|1993|247909.0|       2|\n",
            "|United States|2014|448216.0|       2|\n",
            "|United States|2013|458711.0|       2|\n",
            "|United States|2012|433505.0|       2|\n",
            "|United States|2011|382566.0|       2|\n",
            "|United States|2010|406606.0|       2|\n",
            "|United States|2009|296903.0|       2|\n",
            "+-------------+----+--------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRaXfT0G_Yv3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3545c36-427c-4020-935e-0abb1f4f6d69"
      },
      "source": [
        "df_filter = df.where((df['quantity'] > 184264) & (df['country'] != 'United States'))\n",
        "df_filter.show()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+--------+--------+\n",
            "|country|year|quantity|category|\n",
            "+-------+----+--------+--------+\n",
            "|Germany|2014|311259.0|       7|\n",
            "|Germany|2013|287845.0|       7|\n",
            "|Germany|2012|268856.0|       7|\n",
            "|Germany|2011|216897.0|       7|\n",
            "|Germany|2014|311259.0|       7|\n",
            "|Germany|2013|287845.0|       7|\n",
            "|Germany|2012|268856.0|       7|\n",
            "|Germany|2011|216897.0|       7|\n",
            "|Germany|2014|232451.0|       7|\n",
            "|Germany|2013|217991.0|       7|\n",
            "|Germany|2012|192441.0|       7|\n",
            "|Germany|2014|232451.0|       7|\n",
            "|Germany|2013|217991.0|       7|\n",
            "|Germany|2012|192441.0|       7|\n",
            "| Canada|2013|191861.0|      10|\n",
            "| Canada|2007|202060.0|      10|\n",
            "| Canada|2006|203142.0|      10|\n",
            "| Canada|2005|224001.0|      10|\n",
            "| Canada|2004|236803.0|      10|\n",
            "| Canada|2003|226291.0|      10|\n",
            "+-------+----+--------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXa1U_hMCZiL"
      },
      "source": [
        "# Практика 3. Выведите список всех, товаров, которых хоть когда-то было больше 5-ти штук\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkNPdiNuCYzR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9325ca3-932f-43c1-ffc6-3ccf0833836d"
      },
      "source": [
        "df_practice.show()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+----+-------+------+-----+-----+----+\n",
            "|Year|Month|  ID|Product|Amount|Price|Total|Cost|\n",
            "+----+-----+----+-------+------+-----+-----+----+\n",
            "|2017|    1|t001|     A1|     7| 2904|20328|1200|\n",
            "|2017|    1|t002|     A2|     2| 1896| 3792|1100|\n",
            "|2017|    2|t003|     A1|     5| 2904|14520|1200|\n",
            "|2017|    2|t004|     A4|     1| 8618| 8618|4200|\n",
            "|2017|    2|t005|     A5|     3| 5175|15525| 500|\n",
            "|2017|    2|t006|     _6|     4| 3500|14000| 200|\n",
            "|2017|    3|t007|     _3|     6| 1265| 7590| 200|\n",
            "|2017|    3|t008|     _5|     2| 5175|10350|1200|\n",
            "|2017|    4|t009|     _8|     3| 3760|11280|1000|\n",
            "|2017|    4|t010|     _4|     2| 8618|17236|3400|\n",
            "|2017|    4|t011|     _2|     4| 1896| 7584| 800|\n",
            "|2017|    4|t012|     _5|     5| 5175|25875| 700|\n",
            "|2017|    4|t013|     _8|     3| 3760|11280|1200|\n",
            "|2017|    4|t014|     _4|     1| 8618| 8618| 250|\n",
            "|2017|    5|t015|     _2|     2| 1896| 3792| 650|\n",
            "|2017|    5|t016|     A4|     3| 8618|25854|2400|\n",
            "|2017|    5|t017|     A5|     2| 5175|10350|1200|\n",
            "|2017|    5|t018|     _6|     4| 3500|14000|1200|\n",
            "|2017|    5|t019|     _3|     5| 1265| 6325| 200|\n",
            "|2017|    5|t020|     _5|     6| 5175|31050| 800|\n",
            "+----+-----+----+-------+------+-----+-----+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_practice.where((df_practice['Amount'] > 5)).select('Product').distinct().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uF52wmTXYsO_",
        "outputId": "f787a02f-441b-4ab3-f122-b97f85cba63d"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+\n",
            "|Product|\n",
            "+-------+\n",
            "|     _5|\n",
            "|     _2|\n",
            "|     _8|\n",
            "|     _3|\n",
            "|     A5|\n",
            "|     A1|\n",
            "+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pr_max.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSwPzTZXaaZX",
        "outputId": "191a4281-6305-41cc-84ad-fcba02317bf4"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------+\n",
            "|Product|max(Amount)|\n",
            "+-------+-----------+\n",
            "|     _5|          6|\n",
            "|     _2|          8|\n",
            "|     A2|          2|\n",
            "|     _8|         10|\n",
            "|     _3|          7|\n",
            "|     _4|          3|\n",
            "|     _6|          4|\n",
            "|     A4|          3|\n",
            "|     A5|          7|\n",
            "|     A1|          9|\n",
            "+-------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pr_max.where((df_pr_max['max(Amount)'] > 5)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euu8qn__ahN9",
        "outputId": "12ed010b-d052-49ae-b93a-d8684c7f8465"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------+\n",
            "|Product|max(Amount)|\n",
            "+-------+-----------+\n",
            "|     _5|          6|\n",
            "|     _2|          8|\n",
            "|     _8|         10|\n",
            "|     _3|          7|\n",
            "|     A5|          7|\n",
            "|     A1|          9|\n",
            "+-------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPtzrDNLARKa"
      },
      "source": [
        "## SQL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XBmRZQV_w0T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aae41145-de66-46f9-af7b-9c1101808d08"
      },
      "source": [
        "df.show()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+--------+--------+\n",
            "|country|year|quantity|category|\n",
            "+-------+----+--------+--------+\n",
            "|Austria|1996|     5.0|       1|\n",
            "|Austria|1995|    17.0|       1|\n",
            "|Belgium|2014|     0.0|       1|\n",
            "|Belgium|2013|     0.0|       1|\n",
            "|Belgium|2012|    35.0|       1|\n",
            "|Belgium|2011|    25.0|       1|\n",
            "|Belgium|2010|    22.0|       1|\n",
            "|Belgium|2009|    45.0|       1|\n",
            "|Czechia|1998|     1.0|       1|\n",
            "|Czechia|1995|     7.0|       1|\n",
            "|Finland|2010|     9.0|       1|\n",
            "|Finland|2009|    13.0|       1|\n",
            "|Finland|2008|    39.0|       1|\n",
            "|Finland|2007|    21.0|       1|\n",
            "|Finland|2006|     0.0|       1|\n",
            "|Finland|2005|     0.0|       1|\n",
            "|Finland|2004|     0.0|       1|\n",
            "|Finland|2003|     0.0|       1|\n",
            "|Finland|2002|     0.0|       1|\n",
            "|Finland|2001|     0.0|       1|\n",
            "+-------+----+--------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ty8lF2PMAUhb"
      },
      "source": [
        "df.createOrReplaceTempView('power')"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgqTlx1YAYU2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35c8f299-fc2f-4e42-cd7a-f9174ae8f0fc"
      },
      "source": [
        "spark.sql('SELECT * FROM power').show()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+--------+--------+\n",
            "|country|year|quantity|category|\n",
            "+-------+----+--------+--------+\n",
            "|Austria|1996|     5.0|       1|\n",
            "|Austria|1995|    17.0|       1|\n",
            "|Belgium|2014|     0.0|       1|\n",
            "|Belgium|2013|     0.0|       1|\n",
            "|Belgium|2012|    35.0|       1|\n",
            "|Belgium|2011|    25.0|       1|\n",
            "|Belgium|2010|    22.0|       1|\n",
            "|Belgium|2009|    45.0|       1|\n",
            "|Czechia|1998|     1.0|       1|\n",
            "|Czechia|1995|     7.0|       1|\n",
            "|Finland|2010|     9.0|       1|\n",
            "|Finland|2009|    13.0|       1|\n",
            "|Finland|2008|    39.0|       1|\n",
            "|Finland|2007|    21.0|       1|\n",
            "|Finland|2006|     0.0|       1|\n",
            "|Finland|2005|     0.0|       1|\n",
            "|Finland|2004|     0.0|       1|\n",
            "|Finland|2003|     0.0|       1|\n",
            "|Finland|2002|     0.0|       1|\n",
            "|Finland|2001|     0.0|       1|\n",
            "+-------+----+--------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jENpgOPmAjLy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74250c9e-7644-4ff8-b94f-067e8a4f52e4"
      },
      "source": [
        "spark.sql('SELECT country, sum(quantity) FROM power GROUP BY country').show()"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+--------------------+\n",
            "|           country|       sum(quantity)|\n",
            "+------------------+--------------------+\n",
            "|     Côte d'Ivoire| 2.815485732456253E7|\n",
            "|              Chad|  3796498.7491319943|\n",
            "|          Paraguay|     1.23209483765E7|\n",
            "|          Anguilla|   20529.34999999997|\n",
            "|             Yemen|1.8178937740390217E8|\n",
            "|State of Palestine|  1318668.0123446316|\n",
            "|           Senegal|   6944395.348079733|\n",
            "|            Sweden|1.3456236759933385E8|\n",
            "|        Cabo Verde|   88130.27080000004|\n",
            "|          Kiribati|   6450.091429000002|\n",
            "|            Guyana|   772150.6722661877|\n",
            "|       Philippines|  8.45277094530091E7|\n",
            "|           Eritrea|   918454.1476713057|\n",
            "|            Jersey|  142744.73085845588|\n",
            "|             Tonga|  16350.450516472933|\n",
            "|          Djibouti|  130946.11799999996|\n",
            "|         Singapore| 4.701454062703839E7|\n",
            "|          Malaysia| 8.356959770425016E8|\n",
            "|              Fiji|  400739.80509911076|\n",
            "|            Turkey| 3.500108256564667E8|\n",
            "+------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Cj3YhNoCkzK"
      },
      "source": [
        "## Соединение\n",
        "from pyspark.sql import Row"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKHz1geoCtyb"
      },
      "source": [
        "row1 = Row(\"name\", \"pet\", \"count\")\n",
        "row2 = Row(\"name\", \"pet2\", \"count2\")"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54wmHoIkCxiA"
      },
      "source": [
        "df1 = sc.parallelize([\n",
        "    row1(\"Sue\", \"cat\", 16),\n",
        "    row1(\"Kim\", \"dog\", 1),\n",
        "    row1(\"Bob\", \"fish\", 5),\n",
        "    row1(\"Libuse\", \"horse\", 1)\n",
        "    ]).toDF()\n",
        "\n",
        "df2 = sc.parallelize([\n",
        "    row2(\"Sue\", \"eagle\", 2),\n",
        "    row2(\"Kim\", \"ant\", 179),\n",
        "    row2(\"Bob\", \"lizard\", 5),\n",
        "    row2(\"Ferdinand\", \"bees\", 23)\n",
        "    ]).toDF()"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XM0PeqvC1ks",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59aa8076-12b3-49cb-f892-aab69a847167"
      },
      "source": [
        "df1.show()"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+-----+\n",
            "|  name|  pet|count|\n",
            "+------+-----+-----+\n",
            "|   Sue|  cat|   16|\n",
            "|   Kim|  dog|    1|\n",
            "|   Bob| fish|    5|\n",
            "|Libuse|horse|    1|\n",
            "+------+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGkBbkOpC3_h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9af00f91-b8d8-4759-b149-9480caf2c6bb"
      },
      "source": [
        "df2.show()"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------+------+\n",
            "|     name|  pet2|count2|\n",
            "+---------+------+------+\n",
            "|      Sue| eagle|     2|\n",
            "|      Kim|   ant|   179|\n",
            "|      Bob|lizard|     5|\n",
            "|Ferdinand|  bees|    23|\n",
            "+---------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMHYaIc3C5pT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efb1fda2-9a5b-4d33-8dc4-e25acc1a555b"
      },
      "source": [
        "df1.join(df2, 'name', how='inner').show()"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+-----+------+------+\n",
            "|name| pet|count|  pet2|count2|\n",
            "+----+----+-----+------+------+\n",
            "| Bob|fish|    5|lizard|     5|\n",
            "| Kim| dog|    1|   ant|   179|\n",
            "| Sue| cat|   16| eagle|     2|\n",
            "+----+----+-----+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLqwPLL_DBJP"
      },
      "source": [
        "## Практика 4. При помощи операции соединения выведите максимальное, минимальное и среднее (avg) количество (Amount) по продукту"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1b6U2XYDAQe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57548f93-2126-4aa9-da30-d1b217f41827"
      },
      "source": [
        "df_pr_max.show()"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------+\n",
            "|Product|max(Amount)|\n",
            "+-------+-----------+\n",
            "|     _5|          6|\n",
            "|     _2|          8|\n",
            "|     A2|          2|\n",
            "|     _8|         10|\n",
            "|     _3|          7|\n",
            "|     _4|          3|\n",
            "|     _6|          4|\n",
            "|     A4|          3|\n",
            "|     A5|          7|\n",
            "|     A1|          9|\n",
            "+-------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pr_min_max = df_pr_max.join(df_pr_min, on = 'Product', how = 'outer')\n",
        "df_pr_avg = df_practice.groupby('Product').avg('Amount')\n",
        "df_pr_min_max.join(df_pr_avg, on = 'Product', how = 'inner').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9MhKGp0cZQt",
        "outputId": "de44e825-8615-47d7-f3ba-3d83a887dd67"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------+-----------+------------------+\n",
            "|Product|max(Amount)|min(Amount)|       avg(Amount)|\n",
            "+-------+-----------+-----------+------------------+\n",
            "|     A1|          9|          2|               5.6|\n",
            "|     A2|          2|          2|               2.0|\n",
            "|     A4|          3|          1|               2.0|\n",
            "|     A5|          7|          2|               4.0|\n",
            "|     _2|          8|          1|              4.75|\n",
            "|     _3|          7|          2| 4.285714285714286|\n",
            "|     _4|          3|          1|               2.0|\n",
            "|     _5|          6|          1|3.5454545454545454|\n",
            "|     _6|          4|          4|               4.0|\n",
            "|     _8|         10|          1|               3.5|\n",
            "+-------+-----------+-----------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nrz0MQafAuNE"
      },
      "source": [
        "## Визуализация"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zr1qsEHkApOt"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "5y_8WsiFeBHl",
        "outputId": "77129713-6fa5-4f33-8217-83558d78a206"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.sql.dataframe.DataFrame</b><br/>def __init__(jdf: JavaObject, sql_ctx: Union[&#x27;SQLContext&#x27;, &#x27;SparkSession&#x27;])</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/spark-3.5.4-bin-hadoop3/python/pyspark/sql/dataframe.py</a>A distributed collection of data grouped into named columns.\n",
              "\n",
              ".. versionadded:: 1.3.0\n",
              "\n",
              ".. versionchanged:: 3.4.0\n",
              "    Supports Spark Connect.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "A :class:`DataFrame` is equivalent to a relational table in Spark SQL,\n",
              "and can be created using various functions in :class:`SparkSession`:\n",
              "\n",
              "&gt;&gt;&gt; people = spark.createDataFrame([\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 40, &quot;name&quot;: &quot;Hyukjin Kwon&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 50},\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 50, &quot;name&quot;: &quot;Takuya Ueshin&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 100},\n",
              "...     {&quot;deptId&quot;: 2, &quot;age&quot;: 60, &quot;name&quot;: &quot;Xinrong Meng&quot;, &quot;gender&quot;: &quot;F&quot;, &quot;salary&quot;: 150},\n",
              "...     {&quot;deptId&quot;: 3, &quot;age&quot;: 20, &quot;name&quot;: &quot;Haejoon Lee&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 200}\n",
              "... ])\n",
              "\n",
              "Once created, it can be manipulated using the various domain-specific-language\n",
              "(DSL) functions defined in: :class:`DataFrame`, :class:`Column`.\n",
              "\n",
              "To select a column from the :class:`DataFrame`, use the apply method:\n",
              "\n",
              "&gt;&gt;&gt; age_col = people.age\n",
              "\n",
              "A more concrete example:\n",
              "\n",
              "&gt;&gt;&gt; # To create DataFrame using SparkSession\n",
              "... department = spark.createDataFrame([\n",
              "...     {&quot;id&quot;: 1, &quot;name&quot;: &quot;PySpark&quot;},\n",
              "...     {&quot;id&quot;: 2, &quot;name&quot;: &quot;ML&quot;},\n",
              "...     {&quot;id&quot;: 3, &quot;name&quot;: &quot;Spark SQL&quot;}\n",
              "... ])\n",
              "\n",
              "&gt;&gt;&gt; people.filter(people.age &gt; 30).join(\n",
              "...     department, people.deptId == department.id).groupBy(\n",
              "...     department.name, &quot;gender&quot;).agg({&quot;salary&quot;: &quot;avg&quot;, &quot;age&quot;: &quot;max&quot;}).show()\n",
              "+-------+------+-----------+--------+\n",
              "|   name|gender|avg(salary)|max(age)|\n",
              "+-------+------+-----------+--------+\n",
              "|     ML|     F|      150.0|      60|\n",
              "|PySpark|     M|       75.0|      50|\n",
              "+-------+------+-----------+--------+\n",
              "\n",
              "Notes\n",
              "-----\n",
              "A DataFrame should only be created as described above. It should not be directly\n",
              "created via using the constructor.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 80);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8d78LMDA4SY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0de8225a-9848-4c90-a0f4-9c96b6bf0d91"
      },
      "source": [
        "to_show = df.groupby('year').sum('quantity').orderBy('year')\n",
        "to_show.show()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------------------+\n",
            "|year|       sum(quantity)|\n",
            "+----+--------------------+\n",
            "|1990|2.781426135733307E10|\n",
            "|1991| 2.466541930678139E9|\n",
            "|1992|2.1419483655120907E9|\n",
            "|1993|1.818040678302332...|\n",
            "|1994| 2.286637409479232E9|\n",
            "|1995|1.8993733981039996E9|\n",
            "|1996| 1.276732195368936E9|\n",
            "|1997|2.368193080700125...|\n",
            "|1998| 8.729463830731297E9|\n",
            "|1999| 7.766232101772736E9|\n",
            "|2000| 7.004882006062636E9|\n",
            "|2001|4.0475256363267155E9|\n",
            "|2002| 3.812004491308077E9|\n",
            "|2003| 1.407111379702272E9|\n",
            "|2004|1.4498832309942997E9|\n",
            "|2005|1.623457574857694...|\n",
            "|2006|1.5714035023136258E9|\n",
            "|2007| 9.477595462966421E9|\n",
            "|2008|1.288885727194202...|\n",
            "|2009|1.6234129606657305E9|\n",
            "+----+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(to_show)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "p-YhZP1Bee79",
        "outputId": "4c6e5b0a-a465-4c37-b1e4-63369ee16331"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.sql.dataframe.DataFrame</b><br/>def __init__(jdf: JavaObject, sql_ctx: Union[&#x27;SQLContext&#x27;, &#x27;SparkSession&#x27;])</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/spark-3.5.4-bin-hadoop3/python/pyspark/sql/dataframe.py</a>A distributed collection of data grouped into named columns.\n",
              "\n",
              ".. versionadded:: 1.3.0\n",
              "\n",
              ".. versionchanged:: 3.4.0\n",
              "    Supports Spark Connect.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "A :class:`DataFrame` is equivalent to a relational table in Spark SQL,\n",
              "and can be created using various functions in :class:`SparkSession`:\n",
              "\n",
              "&gt;&gt;&gt; people = spark.createDataFrame([\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 40, &quot;name&quot;: &quot;Hyukjin Kwon&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 50},\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 50, &quot;name&quot;: &quot;Takuya Ueshin&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 100},\n",
              "...     {&quot;deptId&quot;: 2, &quot;age&quot;: 60, &quot;name&quot;: &quot;Xinrong Meng&quot;, &quot;gender&quot;: &quot;F&quot;, &quot;salary&quot;: 150},\n",
              "...     {&quot;deptId&quot;: 3, &quot;age&quot;: 20, &quot;name&quot;: &quot;Haejoon Lee&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 200}\n",
              "... ])\n",
              "\n",
              "Once created, it can be manipulated using the various domain-specific-language\n",
              "(DSL) functions defined in: :class:`DataFrame`, :class:`Column`.\n",
              "\n",
              "To select a column from the :class:`DataFrame`, use the apply method:\n",
              "\n",
              "&gt;&gt;&gt; age_col = people.age\n",
              "\n",
              "A more concrete example:\n",
              "\n",
              "&gt;&gt;&gt; # To create DataFrame using SparkSession\n",
              "... department = spark.createDataFrame([\n",
              "...     {&quot;id&quot;: 1, &quot;name&quot;: &quot;PySpark&quot;},\n",
              "...     {&quot;id&quot;: 2, &quot;name&quot;: &quot;ML&quot;},\n",
              "...     {&quot;id&quot;: 3, &quot;name&quot;: &quot;Spark SQL&quot;}\n",
              "... ])\n",
              "\n",
              "&gt;&gt;&gt; people.filter(people.age &gt; 30).join(\n",
              "...     department, people.deptId == department.id).groupBy(\n",
              "...     department.name, &quot;gender&quot;).agg({&quot;salary&quot;: &quot;avg&quot;, &quot;age&quot;: &quot;max&quot;}).show()\n",
              "+-------+------+-----------+--------+\n",
              "|   name|gender|avg(salary)|max(age)|\n",
              "+-------+------+-----------+--------+\n",
              "|     ML|     F|      150.0|      60|\n",
              "|PySpark|     M|       75.0|      50|\n",
              "+-------+------+-----------+--------+\n",
              "\n",
              "Notes\n",
              "-----\n",
              "A DataFrame should only be created as described above. It should not be directly\n",
              "created via using the constructor.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 80);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24dKhvwoAyP8"
      },
      "source": [
        "pd_df = to_show.toPandas()"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(pd_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "ExKuMTZjeKMk",
        "outputId": "d799a5bd-ba3a-406a-a2ea-86d9339bf186"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pandas.core.frame.DataFrame</b><br/>def __init__(data=None, index: Axes | None=None, columns: Axes | None=None, dtype: Dtype | None=None, copy: bool | None=None) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py</a>Two-dimensional, size-mutable, potentially heterogeneous tabular data.\n",
              "\n",
              "Data structure also contains labeled axes (rows and columns).\n",
              "Arithmetic operations align on both row and column labels. Can be\n",
              "thought of as a dict-like container for Series objects. The primary\n",
              "pandas data structure.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "data : ndarray (structured or homogeneous), Iterable, dict, or DataFrame\n",
              "    Dict can contain Series, arrays, constants, dataclass or list-like objects. If\n",
              "    data is a dict, column order follows insertion-order. If a dict contains Series\n",
              "    which have an index defined, it is aligned by its index. This alignment also\n",
              "    occurs if data is a Series or a DataFrame itself. Alignment is done on\n",
              "    Series/DataFrame inputs.\n",
              "\n",
              "    If data is a list of dicts, column order follows insertion-order.\n",
              "\n",
              "index : Index or array-like\n",
              "    Index to use for resulting frame. Will default to RangeIndex if\n",
              "    no indexing information part of input data and no index provided.\n",
              "columns : Index or array-like\n",
              "    Column labels to use for resulting frame when data does not have them,\n",
              "    defaulting to RangeIndex(0, 1, 2, ..., n). If data contains column labels,\n",
              "    will perform column selection instead.\n",
              "dtype : dtype, default None\n",
              "    Data type to force. Only a single dtype is allowed. If None, infer.\n",
              "copy : bool or None, default None\n",
              "    Copy data from inputs.\n",
              "    For dict data, the default of None behaves like ``copy=True``.  For DataFrame\n",
              "    or 2d ndarray input, the default of None behaves like ``copy=False``.\n",
              "    If data is a dict containing one or more Series (possibly of different dtypes),\n",
              "    ``copy=False`` will ensure that these inputs are not copied.\n",
              "\n",
              "    .. versionchanged:: 1.3.0\n",
              "\n",
              "See Also\n",
              "--------\n",
              "DataFrame.from_records : Constructor from tuples, also record arrays.\n",
              "DataFrame.from_dict : From dicts of Series, arrays, or dicts.\n",
              "read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
              "read_table : Read general delimited file into DataFrame.\n",
              "read_clipboard : Read text from clipboard into DataFrame.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "Please reference the :ref:`User Guide &lt;basics.dataframe&gt;` for more information.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "Constructing DataFrame from a dictionary.\n",
              "\n",
              "&gt;&gt;&gt; d = {&#x27;col1&#x27;: [1, 2], &#x27;col2&#x27;: [3, 4]}\n",
              "&gt;&gt;&gt; df = pd.DataFrame(data=d)\n",
              "&gt;&gt;&gt; df\n",
              "   col1  col2\n",
              "0     1     3\n",
              "1     2     4\n",
              "\n",
              "Notice that the inferred dtype is int64.\n",
              "\n",
              "&gt;&gt;&gt; df.dtypes\n",
              "col1    int64\n",
              "col2    int64\n",
              "dtype: object\n",
              "\n",
              "To enforce a single dtype:\n",
              "\n",
              "&gt;&gt;&gt; df = pd.DataFrame(data=d, dtype=np.int8)\n",
              "&gt;&gt;&gt; df.dtypes\n",
              "col1    int8\n",
              "col2    int8\n",
              "dtype: object\n",
              "\n",
              "Constructing DataFrame from a dictionary including Series:\n",
              "\n",
              "&gt;&gt;&gt; d = {&#x27;col1&#x27;: [0, 1, 2, 3], &#x27;col2&#x27;: pd.Series([2, 3], index=[2, 3])}\n",
              "&gt;&gt;&gt; pd.DataFrame(data=d, index=[0, 1, 2, 3])\n",
              "   col1  col2\n",
              "0     0   NaN\n",
              "1     1   NaN\n",
              "2     2   2.0\n",
              "3     3   3.0\n",
              "\n",
              "Constructing DataFrame from numpy ndarray:\n",
              "\n",
              "&gt;&gt;&gt; df2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\n",
              "...                    columns=[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;])\n",
              "&gt;&gt;&gt; df2\n",
              "   a  b  c\n",
              "0  1  2  3\n",
              "1  4  5  6\n",
              "2  7  8  9\n",
              "\n",
              "Constructing DataFrame from a numpy ndarray that has labeled columns:\n",
              "\n",
              "&gt;&gt;&gt; data = np.array([(1, 2, 3), (4, 5, 6), (7, 8, 9)],\n",
              "...                 dtype=[(&quot;a&quot;, &quot;i4&quot;), (&quot;b&quot;, &quot;i4&quot;), (&quot;c&quot;, &quot;i4&quot;)])\n",
              "&gt;&gt;&gt; df3 = pd.DataFrame(data, columns=[&#x27;c&#x27;, &#x27;a&#x27;])\n",
              "...\n",
              "&gt;&gt;&gt; df3\n",
              "   c  a\n",
              "0  3  1\n",
              "1  6  4\n",
              "2  9  7\n",
              "\n",
              "Constructing DataFrame from dataclass:\n",
              "\n",
              "&gt;&gt;&gt; from dataclasses import make_dataclass\n",
              "&gt;&gt;&gt; Point = make_dataclass(&quot;Point&quot;, [(&quot;x&quot;, int), (&quot;y&quot;, int)])\n",
              "&gt;&gt;&gt; pd.DataFrame([Point(0, 0), Point(0, 3), Point(2, 3)])\n",
              "   x  y\n",
              "0  0  0\n",
              "1  0  3\n",
              "2  2  3\n",
              "\n",
              "Constructing DataFrame from Series/DataFrame:\n",
              "\n",
              "&gt;&gt;&gt; ser = pd.Series([1, 2, 3], index=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;])\n",
              "&gt;&gt;&gt; df = pd.DataFrame(data=ser, index=[&quot;a&quot;, &quot;c&quot;])\n",
              "&gt;&gt;&gt; df\n",
              "   0\n",
              "a  1\n",
              "c  3\n",
              "\n",
              "&gt;&gt;&gt; df1 = pd.DataFrame([1, 2, 3], index=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;], columns=[&quot;x&quot;])\n",
              "&gt;&gt;&gt; df2 = pd.DataFrame(data=df1, index=[&quot;a&quot;, &quot;c&quot;])\n",
              "&gt;&gt;&gt; df2\n",
              "   x\n",
              "a  1\n",
              "c  3</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 509);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsNS_OWxA0cS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "8d520df0-4f26-4674-a02c-ee68b4be5ceb"
      },
      "source": [
        "pd_df['sum(quantity)'].plot()"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 109
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7-hNianA7Gb"
      },
      "source": [
        "years = to_show[['year']].collect()\n",
        "sums = to_show[['sum(quantity)']].collect()"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "years"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7VPS9e9elM_",
        "outputId": "ffe6ffbb-7ae1-48f0-e0ea-4b9d3bb1c9e6"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(year=1990),\n",
              " Row(year=1991),\n",
              " Row(year=1992),\n",
              " Row(year=1993),\n",
              " Row(year=1994),\n",
              " Row(year=1995),\n",
              " Row(year=1996),\n",
              " Row(year=1997),\n",
              " Row(year=1998),\n",
              " Row(year=1999),\n",
              " Row(year=2000),\n",
              " Row(year=2001),\n",
              " Row(year=2002),\n",
              " Row(year=2003),\n",
              " Row(year=2004),\n",
              " Row(year=2005),\n",
              " Row(year=2006),\n",
              " Row(year=2007),\n",
              " Row(year=2008),\n",
              " Row(year=2009),\n",
              " Row(year=2010),\n",
              " Row(year=2011),\n",
              " Row(year=2012),\n",
              " Row(year=2013),\n",
              " Row(year=2014)]"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rz0NWYznA_nw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "4a267ed7-77e0-4d3b-fe86-6f99db24a868"
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(years, sums)\n",
        "plt.show()"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OA44u9RCDO0W"
      },
      "source": [
        "# Домашнее задание\n",
        "- Скачайте dataset iris https://drive.google.com/file/d/18ksAxTxBkp15LToEg46BHhwp3sPIoeUU/view?usp=sharing\n",
        "- Решите домашнее задание - https://colab.research.google.com/drive/1bFOzJNdQzITORtur_m0utqfDJ0QbGe7D?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz0L_tE9Fvls"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}